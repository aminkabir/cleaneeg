{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be58c31a-9193-4030-816f-cf2cfb6d58da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CleanEEG: Automated Resting-State EEG Preprocessing Tutorial\n",
    "This tutorial demonstrates the complete CleanEEG preprocessing pipeline using MNE-Python and complementary libraries. Based on the DISCOVER-EEG framework, it covers all preprocessing steps with quality assessment metrics including Signal-to-Noise Ratio (SNR) and Power Spectral Density (PSD) visualization after each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-of-contents",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Installation and Setup\n",
    "2. Quality Assessment Functions\n",
    "3. Loading EEG Data\n",
    "4. Channel Montage Setup\n",
    "5. Preprocessing Pipeline\n",
    "   - Line Noise Removal (DSS)\n",
    "   - Bandpass Filter\n",
    "   - Downsample Data\n",
    "   - Bad Channel Rejection (PREP)\n",
    "   - Independent Component Analysis (ICA)\n",
    "   - Bad Channel Interpolation\n",
    "   - Bad Time Segments Removal (ASR)\n",
    "6. Final Quality Assessment\n",
    "7. Saving Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a6625-e62b-40e5-8ea4-9fc809f650d7",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup\n",
    "\n",
    "### Option 1: Using Conda Environment (Recommended)\n",
    "\n",
    "Create a conda environment with all dependencies:\n",
    "\n",
    "```bash\n",
    "# Create environment from the provided environment.yml\n",
    "conda env create -f environment.yml\n",
    "conda activate cleaneeg\n",
    "```\n",
    "\n",
    "### Option 2: Using Pip Environment\n",
    "\n",
    "Create a virtual environment and install dependencies:\n",
    "\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python -m venv cleaneeg_env\n",
    "source cleaneeg_env/bin/activate  # On Windows: cleaneeg_env\\Scripts\\activate\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Option 3: Install in Current Environment (Jupyter/Colab)\n",
    "\n",
    "If you're running this in Jupyter or Google Colab, you can install packages directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae8259-43fd-49dd-8d8b-624575c2042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for EEG processing and visualization\n",
    "\n",
    "# Core EEG/MEG analysis packages\n",
    "!pip install mne==1.5.0             # Core package for EEG/MEG data analysis\n",
    "!pip install mne-icalabel==0.5.0    # For automatic classification of ICA components\n",
    "\n",
    "# Automatic bad-channel detection and denoising\n",
    "!pip install pyprep>=0.4.0          # For automatic bad channel detection\n",
    "!pip install meegkit>=0.1.9         # For advanced denoising methods (DSS, ASR)\n",
    "\n",
    "# File‚Äêformat support\n",
    "!pip install pybv>=0.7.0            # For BrainVision file support\n",
    "!pip install eeglabio>=0.0.2        # For EEGLAB file support\n",
    "!pip install edfio>=0.1.0           # For EDF file support\n",
    "!pip install EDFlib-Python>=1.0.8   # For EDF+ file support\n",
    "!pip install h5py>=3.7.0            # For HDF5 file support\n",
    "\n",
    "# Visualization and UI\n",
    "!pip install matplotlib>=3.8,<4.0   # For visualization\n",
    "\n",
    "# Numerical and data-handling libraries\n",
    "!pip install numpy>=2.0.0           # For numerical operations\n",
    "!pip install scipy>=1.10,<2.0       # For scientific computing\n",
    "!pip install pandas>=1.5,<3.0       # For data handling\n",
    "\n",
    "# Utility\n",
    "!pip install tqdm                   # For progress bars (sample data download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-installation",
   "metadata": {},
   "source": [
    "### Verify Installation\n",
    "Let's check that all required packages are installed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required packages are installed\n",
    "import sys\n",
    "\n",
    "required_packages = [\n",
    "    'numpy', 'scipy', 'matplotlib', 'PyQt5', 'mne', 'mne_icalabel', \n",
    "    'pyprep', 'pyriemann', 'sklearn', 'meegkit', 'pybv', 'eeglabio', \n",
    "    'edfio', 'EDFlib', 'h5py', 'pandas'\n",
    "]\n",
    "\n",
    "print(\"Checking packages...\")\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        # Handle special package names\n",
    "        import_name = package\n",
    "        if package == 'sklearn':\n",
    "            import_name = 'sklearn'\n",
    "        elif package == 'mne_icalabel':\n",
    "            import_name = 'mne_icalabel'\n",
    "        elif package == 'EDFlib':\n",
    "            import_name = 'EDFlib'\n",
    "        elif package == 'PyQt5':\n",
    "            import_name = 'PyQt5'\n",
    "            \n",
    "        __import__(import_name)\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package} - missing\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing {len(missing_packages)} packages:\")\n",
    "    for pkg in missing_packages:\n",
    "        print(f\"   - {pkg}\")\n",
    "    print(\"\\nInstall all packages with:\")\n",
    "    print(\"pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\nüéâ All packages ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import ftplib\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set MNE logging level\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-data-section",
   "metadata": {},
   "source": [
    "### Sample Data Download Function\n",
    "If you don't have your own EEG data, we'll implement a function to download sample resting-state EEG data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-data-function",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Sample data download function implementation\n",
    "import ftplib\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def is_dir(ftp: ftplib.FTP, path: str) -> bool:\n",
    "    \"\"\"Check if a path is a directory on the FTP server.\"\"\"\n",
    "    cwd = ftp.pwd()\n",
    "    try:\n",
    "        ftp.cwd(path)\n",
    "        ftp.cwd(cwd)\n",
    "        return True\n",
    "    except ftplib.error_perm:\n",
    "        return False\n",
    "\n",
    "def download_remote(ftp: ftplib.FTP, remote_dir: str, local_dir: Path):\n",
    "    \"\"\"Recursively download files from FTP server.\"\"\"\n",
    "    local_dir.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        ftp.cwd(remote_dir)\n",
    "    except ftplib.error_perm:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        entries = list(ftp.mlsd())\n",
    "    except (ftplib.error_perm, AttributeError):\n",
    "        names = ftp.nlst()\n",
    "        entries = [(name, {'type': 'dir' if is_dir(ftp, f\"{remote_dir}/{name}\") else 'file'})\n",
    "                   for name in names]\n",
    "    \n",
    "    for name, info in tqdm(entries, desc=f\"Scanning {Path(remote_dir).name}\", leave=False):\n",
    "        rpath = f\"{remote_dir}/{name}\"\n",
    "        lpath = local_dir / name\n",
    "        \n",
    "        if info.get('type') == 'dir':\n",
    "            download_remote(ftp, rpath, lpath)\n",
    "        else:\n",
    "            if not lpath.exists():  # Skip if file already exists\n",
    "                try:\n",
    "                    with open(lpath, 'wb') as f:\n",
    "                        ftp.retrbinary(f\"RETR {rpath}\", f.write)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to download {rpath}: {e}\")\n",
    "            else:\n",
    "                print(f\"üìÅ File already exists: {lpath.name}\")\n",
    "\n",
    "def download_sample_data(ftp_host: str,\n",
    "                         ftp_base: str,\n",
    "                         local_base: Path,\n",
    "                         num_subjects: int = 1):\n",
    "    \"\"\"\n",
    "    Download sample EEG data from FTP server.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ftp_host : str\n",
    "        FTP server hostname\n",
    "    ftp_base : str\n",
    "        Base directory on FTP server\n",
    "    local_base : Path\n",
    "        Local directory to save data\n",
    "    num_subjects : int\n",
    "        Number of subjects to download\n",
    "    \"\"\"\n",
    "    print(f\"üåê Connecting to {ftp_host}...\")\n",
    "    \n",
    "    try:\n",
    "        ftp = ftplib.FTP(ftp_host)\n",
    "        ftp.login()\n",
    "        ftp.cwd(ftp_base)\n",
    "        \n",
    "        subjects = ftp.nlst()\n",
    "        if len(subjects) < num_subjects:\n",
    "            raise ValueError(f\"Found only {len(subjects)} subjects, asked for {num_subjects}\")\n",
    "        \n",
    "        chosen = random.sample(subjects, num_subjects)\n",
    "        print(f\"üì• Downloading {num_subjects} random subject(s): {chosen}\\n\")\n",
    "        \n",
    "        for subj in tqdm(chosen, desc=\"Subjects\"):\n",
    "            download_remote(ftp, f\"{ftp_base}/{subj}\", local_base / subj)\n",
    "        \n",
    "        ftp.quit()\n",
    "        print(f\"\\n‚úÖ Download complete. Data is in: {local_base.resolve()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        print(\"   Will use MNE sample data instead...\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Sample data download functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-sample-data",
   "metadata": {},
   "source": [
    "### Download Sample Data (Optional)\n",
    "If you don't have your own resting-state EEG data, you can download sample data from public repositories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192762da-8650-4249-a69d-a91a6fa6c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample EEG data\n",
    "sample_data_downloaded = False\n",
    "sample_data_path = Path('sample_data')\n",
    "\n",
    "print(\"üîç Checking for existing sample data...\")\n",
    "if sample_data_path.exists() and any(sample_data_path.iterdir()):\n",
    "    print(f\"‚úÖ Found existing data in {sample_data_path}\")\n",
    "    sample_data_downloaded = True\n",
    "else:\n",
    "    print(\"üì• No existing data found. Attempting to download sample data...\")\n",
    "    \n",
    "    # Try to download from MPI-Leipzig LEMON dataset\n",
    "    # This dataset contains high-quality resting-state EEG recordings\n",
    "    try:\n",
    "        sample_data_downloaded = download_sample_data(\n",
    "            ftp_host='ftp.gwdg.de',\n",
    "            ftp_base='/pub/misc/MPI-Leipzig_Mind-Brain-Body-LEMON/EEG_MPILMBB_LEMON/EEG_Raw_BIDS_ID',\n",
    "            local_base=sample_data_path,\n",
    "            num_subjects=1  # Download just one subject for this tutorial\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è FTP download failed: {e}\")\n",
    "        sample_data_downloaded = False\n",
    "\n",
    "# Fallback to MNE sample data if download fails\n",
    "if not sample_data_downloaded:\n",
    "    print(\"\\nüîÑ Falling back to MNE sample data...\")\n",
    "    try:\n",
    "        # Use MNE's built-in sample dataset\n",
    "        import mne\n",
    "        sample_data_folder = mne.datasets.sample.data_path()\n",
    "        sample_data_path = sample_data_folder / 'MEG' / 'sample'\n",
    "        print(f\"‚úÖ Will use MNE sample data from: {sample_data_path}\")\n",
    "        sample_data_downloaded = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå MNE sample data also failed: {e}\")\n",
    "        print(\"   Please provide your own EEG data file path in the next section.\")\n",
    "\n",
    "print(f\"\\nüìä Sample data status: {'Available' if sample_data_downloaded else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-functions",
   "metadata": {},
   "source": [
    "## 2. Quality Assessment Functions\n",
    "\n",
    "**Purpose**: Monitor and quantify data quality improvements throughout the preprocessing pipeline.\n",
    "\n",
    "**Why needed**: Preprocessing should improve signal quality, but it's important to verify this objectively. Signal-to-Noise Ratio (SNR) and Power Spectral Density (PSD) provide quantitative metrics to ensure each step is helping rather than hurting data quality.\n",
    "\n",
    "**Methods**: \n",
    "- **SNR calculation**: Compares signal power in neural frequency bands to noise estimates\n",
    "- **PSD visualization**: Shows how preprocessing affects the frequency content of signals\n",
    "- **Progress tracking**: Documents quality changes after each preprocessing step\n",
    "\n",
    "These functions will help us track data quality throughout the preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-assessment-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_snr(raw, freq_bands=None, method='rms'):\n",
    "    \"\"\"\n",
    "    Compute Signal-to-Noise Ratio for EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw : mne.io.Raw\n",
    "        The EEG data\n",
    "    freq_bands : dict\n",
    "        Dictionary of frequency bands to analyze\n",
    "    method : str\n",
    "        Method for SNR calculation ('rms' or 'spectral')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    snr_results : dict\n",
    "        SNR values for different frequency bands\n",
    "    \"\"\"\n",
    "    if freq_bands is None:\n",
    "        freq_bands = {\n",
    "            'delta': (1, 4),\n",
    "            'theta': (4, 8), \n",
    "            'alpha': (8, 13),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 100)\n",
    "        }\n",
    "    \n",
    "    # Get data and sampling frequency\n",
    "    data = raw.get_data()\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    snr_results = {}\n",
    "    \n",
    "    if method == 'spectral':\n",
    "        # Compute PSD\n",
    "        freqs, psd = signal.welch(data, sfreq, nperseg=int(2*sfreq))\n",
    "        \n",
    "        for band_name, (low_freq, high_freq) in freq_bands.items():\n",
    "            # Find frequency indices\n",
    "            freq_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "            \n",
    "            # Signal power in the band\n",
    "            signal_power = np.mean(psd[:, freq_mask], axis=1)\n",
    "            \n",
    "            # Noise estimation (neighboring frequencies)\n",
    "            noise_low = max(0, low_freq - 2)\n",
    "            noise_high = min(freqs[-1], high_freq + 2)\n",
    "            noise_mask = ((freqs >= noise_low) & (freqs < low_freq)) | \\\n",
    "                        ((freqs > high_freq) & (freqs <= noise_high))\n",
    "            \n",
    "            if np.any(noise_mask):\n",
    "                noise_power = np.mean(psd[:, noise_mask], axis=1)\n",
    "                snr = 10 * np.log10(signal_power / (noise_power + 1e-10))\n",
    "            else:\n",
    "                snr = np.full(len(raw.ch_names), np.nan)\n",
    "            \n",
    "            snr_results[band_name] = {\n",
    "                'mean_snr': np.nanmean(snr),\n",
    "                'std_snr': np.nanstd(snr),\n",
    "                'channel_snr': snr\n",
    "            }\n",
    "    \n",
    "    else:  # RMS method\n",
    "        for band_name, (low_freq, high_freq) in freq_bands.items():\n",
    "            # Filter data to frequency band\n",
    "            raw_filtered = raw.copy().filter(low_freq, high_freq, verbose=False)\n",
    "            filtered_data = raw_filtered.get_data()\n",
    "            \n",
    "            # RMS of signal\n",
    "            signal_rms = np.sqrt(np.mean(filtered_data**2, axis=1))\n",
    "            \n",
    "            # Estimate noise from high frequencies (above 80 Hz)\n",
    "            if raw.info['sfreq'] > 160:  # Ensure we can filter above 80 Hz\n",
    "                raw_noise = raw.copy().filter(80, None, verbose=False)\n",
    "                noise_data = raw_noise.get_data()\n",
    "                noise_rms = np.sqrt(np.mean(noise_data**2, axis=1))\n",
    "                snr = 20 * np.log10(signal_rms / (noise_rms + 1e-10))\n",
    "            else:\n",
    "                # Use standard deviation as noise estimate\n",
    "                noise_std = np.std(filtered_data, axis=1)\n",
    "                snr = 20 * np.log10(signal_rms / (noise_std + 1e-10))\n",
    "            \n",
    "            snr_results[band_name] = {\n",
    "                'mean_snr': np.mean(snr),\n",
    "                'std_snr': np.std(snr),\n",
    "                'channel_snr': snr\n",
    "            }\n",
    "    \n",
    "    return snr_results\n",
    "\n",
    "def plot_psd_comparison(raw_list, labels, title=\"Power Spectral Density Comparison\", fmax=80):\n",
    "    \"\"\"\n",
    "    Plot PSD comparison for multiple raw objects.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_list : list\n",
    "        List of mne.io.Raw objects\n",
    "    labels : list\n",
    "        Labels for each raw object\n",
    "    title : str\n",
    "        Plot title\n",
    "    fmax : float\n",
    "        Maximum frequency to plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Red for before, Blue for after\n",
    "    colors = ['red', 'blue'][:len(raw_list)]\n",
    "    \n",
    "    for i, (raw, label, color) in enumerate(zip(raw_list, labels, colors)):\n",
    "        # Compute PSD\n",
    "        psd = raw.compute_psd(fmax=fmax, verbose=False)\n",
    "        \n",
    "        # Plot average across channels\n",
    "        freqs = psd.freqs\n",
    "        psd_data = psd.get_data()\n",
    "        mean_psd = np.mean(psd_data, axis=0)\n",
    "        \n",
    "        ax.semilogy(freqs, mean_psd, label=label, color=color, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Power Spectral Density (V¬≤/Hz)')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_snr_summary(snr_results, step_name):\n",
    "    \"\"\"\n",
    "    Print a formatted summary of SNR results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä SNR Summary - {step_name}:\")\n",
    "    print(\"=\" * 50)\n",
    "    for band, results in snr_results.items():\n",
    "        print(f\"{band.capitalize():>8}: {results['mean_snr']:6.2f} ¬± {results['std_snr']:5.2f} dB\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def plot_processing_summary(processing_log):\n",
    "    \"\"\"\n",
    "    Plot a summary of SNR changes throughout processing.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    steps = list(processing_log.keys())\n",
    "    \n",
    "    for i, band in enumerate(bands):\n",
    "        if i < len(axes):\n",
    "            snr_values = [processing_log[step][band]['mean_snr'] for step in steps]\n",
    "            axes[i].plot(range(len(steps)), snr_values, 'o-', linewidth=2, markersize=8)\n",
    "            axes[i].set_title(f'{band.capitalize()} Band SNR')\n",
    "            axes[i].set_ylabel('SNR (dB)')\n",
    "            axes[i].set_xticks(range(len(steps)))\n",
    "            axes[i].set_xticklabels(steps, rotation=45, ha='right')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove the last subplot if we have 6 subplots but only 5 bands\n",
    "    if len(bands) < len(axes):\n",
    "        fig.delaxes(axes[-1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Quality assessment functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f7e84-085c-4205-b37f-e0a818030ba1",
   "metadata": {},
   "source": [
    "## 3. Loading EEG Data\n",
    "Load your EEG data from various formats supported by MNE-Python (.edf, .vhdr, .bdf, .set, .fif). This cell automatically finds EEG files in your downloaded dataset, checks for common mislabeling issues (like EOG or reference channels incorrectly marked as EEG), and filters to keep only true EEG channels for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b927d0-cf4b-49d5-8b23-97b2d445ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìÅ Load EEG Data\n",
    "\n",
    "# Load EEG data (using already downloaded dataset)\n",
    "print(\"üìÅ Loading EEG data...\")\n",
    "\n",
    "if sample_data_downloaded:\n",
    "    # Find EEG files in downloaded data\n",
    "    eeg_extensions = [\".vhdr\", \".edf\", \".bdf\", \".set\", \".fif\"]\n",
    "    eeg_files = []\n",
    "    \n",
    "    for ext in eeg_extensions:\n",
    "        eeg_files.extend(list(sample_data_path.rglob(f\"*{ext}\")))\n",
    "    \n",
    "    if eeg_files:\n",
    "        # Use the first EEG file found\n",
    "        eeg_file = eeg_files[0]\n",
    "        print(f\"üìÇ Loading: {eeg_file.name}\")\n",
    "        raw = mne.io.read_raw(eeg_file, preload=True)\n",
    "        data_source = f\"Downloaded: {eeg_file.name}\"\n",
    "    else:\n",
    "        # No EEG files found\n",
    "        print(\"‚ùå No EEG files found in downloaded data!\")\n",
    "        raise FileNotFoundError(\"Please check data download above\")\n",
    "else:\n",
    "    print(\"‚ùå No data available!\")\n",
    "    raise FileNotFoundError(\"Please check data download above\")\n",
    "\n",
    "# Check for mislabeled channels before filtering\n",
    "print(\"\\nüîç Checking for mislabeled channels...\")\n",
    "\n",
    "# Common patterns for non-EEG channels that might be labeled as EEG\n",
    "eog_patterns = ['EOG', 'VEOG', 'HEOG', 'EOGH', 'EOGV', 'EOG1', 'EOG2', 'LHEOG', 'RHEOG']\n",
    "ref_patterns = ['REF', 'GND', 'A1', 'A2', 'M1', 'M2', 'TP9', 'TP10']\n",
    "other_patterns = ['ECG', 'EMG', 'RESP', 'TRIG', 'STI']\n",
    "\n",
    "# Check each channel name\n",
    "mislabeled_channels = []\n",
    "for ch_name in raw.ch_names:\n",
    "    ch_upper = ch_name.upper()\n",
    "    \n",
    "    # Check for EOG patterns\n",
    "    for pattern in eog_patterns:\n",
    "        if pattern in ch_upper:\n",
    "            mislabeled_channels.append((ch_name, 'eog'))\n",
    "            break\n",
    "    else:\n",
    "        # Check for reference patterns\n",
    "        for pattern in ref_patterns:\n",
    "            if pattern in ch_upper:\n",
    "                mislabeled_channels.append((ch_name, 'misc'))\n",
    "                break\n",
    "        else:\n",
    "            # Check for other non-EEG patterns\n",
    "            for pattern in other_patterns:\n",
    "                if pattern in ch_upper:\n",
    "                    mislabeled_channels.append((ch_name, 'misc'))\n",
    "                    break\n",
    "\n",
    "# Report and fix mislabeled channels\n",
    "if mislabeled_channels:\n",
    "    print(f\"‚ö†Ô∏è Found {len(mislabeled_channels)} potentially mislabeled channels:\")\n",
    "    for ch_name, suggested_type in mislabeled_channels:\n",
    "        print(f\"   {ch_name} ‚Üí {suggested_type}\")\n",
    "        raw.set_channel_types({ch_name: suggested_type})\n",
    "    print(\"‚úÖ Channel types corrected!\")\n",
    "else:\n",
    "    print(\"‚úÖ All channels appear correctly labeled\")\n",
    "\n",
    "# Check channel types and filter to EEG only\n",
    "channel_types = set(raw.get_channel_types())\n",
    "print(f\"üìä Channel types found: {list(channel_types)}\")\n",
    "\n",
    "if 'eeg' in channel_types:\n",
    "    n_before = len(raw.ch_names)\n",
    "    raw.pick('eeg')\n",
    "    n_after = len(raw.ch_names)\n",
    "    print(f\"üìå Keeping EEG channels: {n_before} ‚Üí {n_after} channels\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No EEG channels detected!\")\n",
    "\n",
    "# Show data summary\n",
    "print(f\"\\nüìã Data Summary:\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Source: {data_source}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Channels: {len(raw.ch_names)} EEG\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Duration: {raw.times[-1]:.1f} seconds\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Sample rate: {raw.info['sfreq']} Hz\")\n",
    "\n",
    "# Initial quality assessment\n",
    "print(\"\\nüîç Initial quality check...\")\n",
    "initial_snr = compute_snr(raw)\n",
    "print_snr_summary(initial_snr, \"Original Data\")\n",
    "\n",
    "# Set up for processing pipeline\n",
    "processing_log = {'Original': initial_snr}\n",
    "raw_versions = {'Original': raw.copy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad106c8c-b907-4f86-8e87-8b2b406578fe",
   "metadata": {},
   "source": [
    "## 4. Channel Montage Setup\n",
    "\n",
    "**Purpose**: Apply a standard electrode montage to provide spatial information about channel locations.\n",
    "\n",
    "**Why needed**: Many preprocessing steps (bad channel detection, interpolation) and analyses (source localization, connectivity) require knowing where each electrode is positioned on the scalp. Without spatial information, we can't determine which channels are neighbors or create topographic maps.\n",
    "\n",
    "**Method**: Match electrode names to standard montage templates (10-20, 10-05, etc.) that define precise coordinates for each electrode position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fad717-175c-4f4f-a646-fa32503c21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üó∫Ô∏è Set Electrode Montage\n",
    "\n",
    "# Create a working copy for processing\n",
    "print(\"üó∫Ô∏è Setting up electrode montage...\")\n",
    "raw_processed = raw.copy()\n",
    "\n",
    "# Try common montages to find best match\n",
    "montages = ['standard_1020', 'standard_1005', 'easycap-M1', 'biosemi64']\n",
    "\n",
    "montage_applied = False\n",
    "for montage_name in montages:\n",
    "    try:\n",
    "        montage = mne.channels.make_standard_montage(montage_name)\n",
    "        raw_processed.set_montage(montage, match_case=False, on_missing='ignore')\n",
    "        \n",
    "        # Check how many channels got positions\n",
    "        n_positioned = sum(1 for ch in raw_processed.info['chs'] if ch['loc'][0] != 0)\n",
    "        match_pct = (n_positioned / len(raw_processed.ch_names)) * 100\n",
    "        \n",
    "        if match_pct > 50:  # At least 50% matched\n",
    "            print(f\"‚úÖ Applied {montage_name}: {n_positioned}/{len(raw_processed.ch_names)} channels positioned ({match_pct:.0f}%)\")\n",
    "            montage_applied = True\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   {montage_name}: {match_pct:.0f}% match - trying next...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   {montage_name}: failed - {e}\")\n",
    "        continue\n",
    "\n",
    "if not montage_applied:\n",
    "    print(\"‚ö†Ô∏è No suitable montage found - continuing without spatial info\")\n",
    "\n",
    "# Show electrode positions if montage was applied\n",
    "if montage_applied:\n",
    "    try:\n",
    "        raw_processed.plot_sensors(show_names=True, sphere='auto')\n",
    "    except:\n",
    "        print(\"üìç Electrode positions set (visualization unavailable)\")\n",
    "\n",
    "print(f\"\\nüìä Setup Summary:\")\n",
    "print(f\"‚îú‚îÄ‚îÄ EEG channels: {len(raw_processed.ch_names)}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Montage: {'Applied' if montage_applied else 'None'}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Ready for preprocessing pipeline\")\n",
    "\n",
    "# Update main processing variable\n",
    "raw = raw_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-pipeline",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Pipeline\n",
    "\n",
    "**Overview**: This section applies the complete CleanEEG preprocessing workflow following the DISCOVER-EEG framework. Each step targets specific types of artifacts while preserving neural signals.\n",
    "\n",
    "**Pipeline Logic**: Steps are ordered to handle the largest artifacts first (line noise, drifts) before more sophisticated analyses (ICA, ASR) that work better on cleaner data. Quality metrics after each step confirm improvements.\n",
    "\n",
    "**Key Principle**: Every preprocessing step should improve signal quality. We'll monitor this with quantitative metrics throughout.\n",
    "\n",
    "Now we'll apply the complete CleanEEG preprocessing pipeline, monitoring quality at each step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "line-noise",
   "metadata": {},
   "source": [
    "### 5.1 Line Noise Removal (Denoising Source Separation)\n",
    "\n",
    "**Purpose**: Remove electrical interference from power lines (50/60 Hz) that contaminates EEG signals.\n",
    "\n",
    "**Why needed**: Power line noise creates strong, narrow-band artifacts that can overwhelm neural signals and distort frequency analysis. This interference comes from electrical equipment and building wiring.\n",
    "\n",
    "**Method**: Denoising Source Separation (DSS) is superior to simple notch filtering because it removes line noise while preserving neural activity at the same frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "line-noise-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meegkit import dss\n",
    "from scipy import signal\n",
    "\n",
    "print(\"‚ö° Removing line noise using Denoising Source Separation (DSS)...\")\n",
    "\n",
    "# Line frequency depends on geographical location:\n",
    "# - 50 Hz: Europe, Asia, Africa, Australia (most of the world)\n",
    "# - 60 Hz: North America, parts of South America, some Pacific islands\n",
    "# Since this dataset was collected in Germany (LEMON dataset), we use 50 Hz\n",
    "line_freq = 50  # Change to 60 if your data is from North America\n",
    "print(f\"‚ö° Removing {line_freq} Hz line noise...\")\n",
    "\n",
    "# Check current line noise level\n",
    "data = raw.get_data()\n",
    "sfreq = raw.info['sfreq']\n",
    "freqs, psd = signal.welch(data, sfreq, nperseg=int(2*sfreq))\n",
    "freq_idx = np.argmin(np.abs(freqs - line_freq))\n",
    "power_before = np.mean(psd[:, freq_idx])\n",
    "\n",
    "# Apply DSS line noise removal\n",
    "try:\n",
    "    print(\"üîß Applying Denoising Source Separation...\")\n",
    "    processed_data, artifacts = dss.dss_line(\n",
    "        data.T,              # DSS expects (time x channels)\n",
    "        fline=line_freq,     # Target frequency\n",
    "        sfreq=sfreq,         # Sampling rate\n",
    "        show=False           # No plots during processing\n",
    "    )\n",
    "    \n",
    "    # Update the raw data\n",
    "    raw._data = processed_data.T  # Convert back to (channels x time)\n",
    "    method_used = \"DSS\"\n",
    "    print(\"‚úÖ DSS successfully applied\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è DSS failed: {e}\")\n",
    "    print(\"üîÑ Using notch filter instead...\")\n",
    "    raw.notch_filter(freqs=[line_freq], verbose=False)\n",
    "    method_used = \"Notch Filter\"\n",
    "    print(\"‚úÖ Notch filter applied\")\n",
    "\n",
    "# Verify noise reduction\n",
    "data_after = raw.get_data()\n",
    "freqs_after, psd_after = signal.welch(data_after, sfreq, nperseg=int(2*sfreq))\n",
    "power_after = np.mean(psd_after[:, freq_idx])\n",
    "reduction_db = 10 * np.log10(power_before / (power_after + 1e-12))\n",
    "\n",
    "print(f\"üìä Line noise reduction: {reduction_db:.1f} dB using {method_used}\")\n",
    "\n",
    "# Store results for comparison\n",
    "raw_versions['After Line Noise'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_line = compute_snr(raw)\n",
    "processing_log['After Line Noise'] = snr_after_line\n",
    "print_snr_summary(snr_after_line, \"After Line Noise Removal\")\n",
    "\n",
    "# Plot before/after comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['Original'], raw_versions['After Line Noise']], \n",
    "    ['Original', 'After Line Noise'],\n",
    "    \"Power Spectral Density: Line Noise Removal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "highpass-filter",
   "metadata": {},
   "source": [
    "### 5.2 Bandpass Filter\n",
    "\n",
    "**Purpose**: Remove slow drifts, baseline shifts, and high-frequency noise from EEG recordings.\n",
    "\n",
    "**Why needed**: EEG amplifiers can introduce very low-frequency drifts (<1 Hz) due to electrode movement, skin conductance changes, and amplifier instabilities. Additionally, high-frequency noise (>100 Hz) from electrical interference, muscle artifacts, and amplifier noise can contaminate the signal. These artifacts can distort analyses and make data appear non-stationary.\n",
    "\n",
    "**Method**: A 1-100 Hz bandpass filter combines:\n",
    "- **Highpass component (1 Hz)**: Removes slow drifts while preserving all neural frequencies of interest (delta waves start at ~1-4 Hz)\n",
    "- **Lowpass component (100 Hz)**: Removes high-frequency noise while retaining all relevant neural oscillations including gamma activity (30-100 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "highpass-filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üîΩ Apply Bandpass Filter\n",
    "\n",
    "# Set filter parameters\n",
    "hp_freq = 1.0   # Remove slow drifts below 1 Hz\n",
    "lp_freq = 100.0 # Remove noise above 100 Hz\n",
    "\n",
    "print(f\"üîΩ Applying {hp_freq}-{lp_freq} Hz bandpass filter...\")\n",
    "\n",
    "# Apply bandpass filter\n",
    "raw.filter(\n",
    "    l_freq=hp_freq,   # High-pass cutoff  \n",
    "    h_freq=lp_freq,   # Low-pass cutoff\n",
    "    method='fir',     # Finite Impulse Response\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Bandpass filter applied: {hp_freq}-{lp_freq} Hz\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After Bandpass'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_bandpass = compute_snr(raw)\n",
    "processing_log['After Bandpass'] = snr_after_bandpass\n",
    "print_snr_summary(snr_after_bandpass, \"After Bandpass Filter\")\n",
    "\n",
    "# Plot before/after comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Line Noise'], raw_versions['After Bandpass']], \n",
    "    ['After Line Noise', 'After Bandpass'],\n",
    "    \"Power Spectral Density: Bandpass Filter Effect\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downsample",
   "metadata": {},
   "source": [
    "### 5.3 Downsample Data\n",
    "\n",
    "**Purpose**: Reduce data size and computational load while preserving all relevant neural information.\n",
    "\n",
    "**Why needed**: Many EEG systems record at very high sampling rates (>1000 Hz) to avoid aliasing, but most EEG analysis only requires frequencies up to 100-200 Hz. High sampling rates create unnecessarily large files and slow processing.\n",
    "\n",
    "**Method**: Downsample to 500 Hz (adequate for frequencies up to 250 Hz) after applying anti-aliasing filters to prevent frequency distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downsampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìâ Downsample Data\n",
    "\n",
    "# Set target sampling rate\n",
    "target_sfreq = 500  # Hz - adequate for EEG analysis\n",
    "original_sfreq = raw.info['sfreq']\n",
    "\n",
    "print(f\"üìâ Checking sampling rate: {original_sfreq} Hz\")\n",
    "\n",
    "# Downsample if necessary\n",
    "if original_sfreq > target_sfreq:\n",
    "    raw.resample(target_sfreq, verbose=False)\n",
    "    reduction = (1 - target_sfreq/original_sfreq) * 100\n",
    "    print(f\"‚úÖ Downsampled to {target_sfreq} Hz (reduced data by {reduction:.1f}%)\")\n",
    "else:\n",
    "    print(f\"‚úÖ No downsampling needed (already {original_sfreq} Hz)\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After Downsample'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_downsample = compute_snr(raw)\n",
    "processing_log['After Downsample'] = snr_after_downsample\n",
    "print_snr_summary(snr_after_downsample, \"After Downsampling\")\n",
    "\n",
    "# Plot before/after comparison (up to new Nyquist frequency)\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Bandpass'], raw_versions['After Downsample']], \n",
    "    ['Before Downsample', 'After Downsample'],\n",
    "    \"Power Spectral Density: Downsampling Effect\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad-channels",
   "metadata": {},
   "source": [
    "### 5.4 Bad Channel Rejection (PREP Pipeline)\n",
    "\n",
    "**Purpose**: Automatically identify and mark electrodes that are not recording valid neural signals.\n",
    "\n",
    "**Why needed**: EEG electrodes can malfunction due to poor skin contact, broken wires, high impedance, or movement artifacts. Bad channels introduce noise and can distort spatial analyses, source localization, and connectivity measures.\n",
    "\n",
    "**Method**: The PREP pipeline uses multiple statistical criteria: flat channels, channels with extreme amplitudes, poor correlation with neighbors, and channels that deviate from robust signal statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad-channel-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üîç Detect Bad Channels\n",
    "\n",
    "print(\"üîç Detecting bad channels...\")\n",
    "\n",
    "try:\n",
    "    # Use PREP pipeline for comprehensive bad channel detection\n",
    "    from pyprep.find_noisy_channels import NoisyChannels\n",
    "    \n",
    "    nd = NoisyChannels(raw, random_state=42)\n",
    "    nd.find_all_bads(ransac=True, channel_wise=True)\n",
    "    bad_channels_raw = nd.get_bads()\n",
    "    \n",
    "    # Clean up bad channels list (convert numpy strings to regular strings)\n",
    "    bad_channels = [str(ch) for ch in bad_channels_raw] if bad_channels_raw else []\n",
    "    \n",
    "    if bad_channels:\n",
    "        print(f\"üö´ PREP detected {len(bad_channels)} bad channels: {bad_channels}\")\n",
    "        raw.info['bads'] = bad_channels\n",
    "    else:\n",
    "        print(\"‚úÖ PREP found no bad channels\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è PREP failed, using statistical method...\")\n",
    "    \n",
    "    # Fallback: detect channels with extreme variance\n",
    "    data = raw.get_data()\n",
    "    channel_vars = np.var(data, axis=1)\n",
    "    \n",
    "    # Find outliers (top/bottom 5% by variance)\n",
    "    high_thresh = np.percentile(channel_vars, 95)\n",
    "    low_thresh = np.percentile(channel_vars, 5)\n",
    "    \n",
    "    bad_channels = []\n",
    "    for i, ch_name in enumerate(raw.ch_names):\n",
    "        if channel_vars[i] > high_thresh or channel_vars[i] < low_thresh:\n",
    "            bad_channels.append(ch_name)\n",
    "    \n",
    "    if bad_channels:\n",
    "        print(f\"üö´ Statistical method found {len(bad_channels)} bad channels: {bad_channels}\")\n",
    "        raw.info['bads'] = bad_channels\n",
    "    else:\n",
    "        print(\"‚úÖ Statistical method found no bad channels\")\n",
    "\n",
    "# Summary\n",
    "total_channels = len(raw.ch_names)\n",
    "n_bad = len(raw.info['bads'])\n",
    "n_good = total_channels - n_bad\n",
    "\n",
    "print(f\"üìä Channel Summary: {n_good}/{total_channels} good channels ({n_bad} marked as bad)\")\n",
    "\n",
    "# Visualize montage with bad channels highlighted\n",
    "if n_bad > 0:\n",
    "    try:\n",
    "        print(\"üó∫Ô∏è Showing electrode positions (bad channels in red)...\")\n",
    "        fig = raw.plot_sensors(\n",
    "            kind='topomap', \n",
    "            show_names=True, \n",
    "            sphere='auto',\n",
    "            title=f'Electrode Positions ({n_bad} bad channels in red)'\n",
    "        )\n",
    "        \n",
    "        # Get the axes and mark bad channels in red\n",
    "        import matplotlib.pyplot as plt\n",
    "        ax = fig.get_axes()[0]\n",
    "        \n",
    "        # Find positions of bad channels and mark them red\n",
    "        pos = raw._get_channel_positions()\n",
    "        if pos is not None:\n",
    "            for i, ch_name in enumerate(raw.ch_names):\n",
    "                if ch_name in raw.info['bads']:\n",
    "                    # Find the channel position and recolor it\n",
    "                    for child in ax.get_children():\n",
    "                        if hasattr(child, 'get_text') and child.get_text() == ch_name:\n",
    "                            child.set_color('red')\n",
    "                            child.set_fontweight('bold')\n",
    "        \n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not plot montage: {e}\")\n",
    "\n",
    "# Store bad channels for later use\n",
    "bad_channels_for_interpolation = raw.info['bads'].copy()\n",
    "print(f\"üíæ Stored {len(bad_channels_for_interpolation)} bad channels for later interpolation\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After Bad Channels'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_bad = compute_snr(raw)\n",
    "processing_log['After Bad Channels'] = snr_after_bad\n",
    "print_snr_summary(snr_after_bad, \"After Bad Channel Detection\")\n",
    "\n",
    "# Plot PSD comparison to show impact of bad channel detection\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Downsample'], raw_versions['After Bad Channels']], \n",
    "    ['Before Bad Channel Detection', 'After Bad Channel Detection'],\n",
    "    \"Power Spectral Density: Bad Channel Detection Effect\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ica",
   "metadata": {},
   "source": [
    "### 5.5 Independent Component Analysis (ICA)\n",
    "\n",
    "**Purpose**: Separate mixed EEG signals into independent components and remove non-neural artifacts.\n",
    "\n",
    "**Why needed**: EEG signals are mixtures of neural activity, muscle artifacts, heart beats, eye movements, and other noise sources. These artifacts can't always be removed by simple filtering and often overlap with neural frequencies.\n",
    "\n",
    "**Method**: ICA decomposes the signal into statistically independent components. ICLabel automatically classifies components as brain activity, muscle, eye blinks, heart beats, or noise, allowing selective removal of artifacts while preserving neural signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ica-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üß† Independent Component Analysis (ICA)\n",
    "\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "\n",
    "print(\"üß† Running ICA for artifact removal...\")\n",
    "\n",
    "try:\n",
    "    # Prepare data for ICA (exclude bad channels, use average reference)\n",
    "    raw_for_ica = raw.copy().pick('eeg', exclude='bads')\n",
    "    raw_for_ica.set_eeg_reference('average', projection=False, verbose=False)\n",
    "    \n",
    "    # Fit ICA\n",
    "    print(\"üîß Fitting ICA components...\")\n",
    "    # Note: ICLabel was trained on extended infomax, but we use fastica for speed\n",
    "    # This may produce a warning, but still gives good results for most datasets\n",
    "    ica = ICA(n_components=None, method='fastica', random_state=42, max_iter='auto')\n",
    "    ica.fit(raw_for_ica, verbose=False)\n",
    "    \n",
    "    # Classify components with ICLabel\n",
    "    print(\"üè∑Ô∏è Classifying components with ICLabel...\")\n",
    "    ic_labels = label_components(raw_for_ica, ica, method='iclabel')\n",
    "    \n",
    "    # Find artifact components to exclude\n",
    "    labels = ic_labels['labels']\n",
    "    probabilities = ic_labels['y_pred_proba']\n",
    "    artifact_types = ['muscle artifact', 'eye blink', 'heart beat', 'line noise', 'channel noise']\n",
    "    \n",
    "    exclude_idx = []\n",
    "    for i, (label, probs) in enumerate(zip(labels, probabilities)):\n",
    "        if label in artifact_types and np.max(probs) > 0.7:  # High confidence artifacts\n",
    "            exclude_idx.append(i)\n",
    "    \n",
    "    # Show only artifact components being excluded\n",
    "    if exclude_idx:\n",
    "        print(f\"üìä Artifact components to exclude ({len(exclude_idx)} total):\")\n",
    "        for i in exclude_idx[:12]:  # Show first 12 excluded components\n",
    "            label = labels[i]\n",
    "            confidence = np.max(probabilities[i])\n",
    "            print(f\"   IC{i:02d}: {label} (confidence: {confidence:.2f}) [EXCLUDED]\")\n",
    "        \n",
    "        if len(exclude_idx) > 12:\n",
    "            print(f\"   ... and {len(exclude_idx)-12} more artifact components\")\n",
    "    else:\n",
    "        print(\"üìä No high-confidence artifact components found\")\n",
    "    \n",
    "    # Apply ICA artifact removal\n",
    "    ica.exclude = exclude_idx\n",
    "    raw = ica.apply(raw, verbose=False)\n",
    "    \n",
    "    print(f\"‚úÖ ICA applied - removed {len(exclude_idx)} artifact components\")\n",
    "    \n",
    "    # Plot excluded component topographies only\n",
    "    if exclude_idx:\n",
    "        try:\n",
    "            fig = ica.plot_components(picks=exclude_idx[:12],  # Show first 12 excluded\n",
    "                                     title=f'Excluded ICA Components ({len(exclude_idx)} total)', \n",
    "                                     show=False)\n",
    "            plt.show()\n",
    "        except:\n",
    "            print(\"üìä Component visualization unavailable\")\n",
    "    else:\n",
    "        print(\"üìä No artifact components to visualize\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ICA failed: {e}\")\n",
    "    print(\"Continuing without ICA artifact removal\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After ICA'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_ica = compute_snr(raw)\n",
    "processing_log['After ICA'] = snr_after_ica\n",
    "print_snr_summary(snr_after_ica, \"After ICA\")\n",
    "\n",
    "# Plot before/after comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Bad Channels'], raw_versions['After ICA']], \n",
    "    ['Before ICA', 'After ICA'],\n",
    "    \"Power Spectral Density: ICA Artifact Removal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpolation",
   "metadata": {},
   "source": [
    "### 5.6 Bad Channel Interpolation\n",
    "\n",
    "**Purpose**: Restore the full electrode array by estimating signals at previously identified bad channel locations.\n",
    "\n",
    "**Why needed**: Many analyses (especially connectivity and source localization) require a complete, uniform electrode montage. Missing channels create gaps in spatial coverage and can bias results toward areas with higher electrode density.\n",
    "\n",
    "**Method**: Spherical spline interpolation uses signals from neighboring good electrodes to estimate what the signal would have been at bad electrode locations, based on the spatial smoothness of scalp potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "channel-interpolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üîß Interpolate Bad Channels\n",
    "\n",
    "print(\"üîß Interpolating bad channels...\")\n",
    "\n",
    "# Use the bad channels identified earlier\n",
    "if 'bad_channels_for_interpolation' in locals() and bad_channels_for_interpolation:\n",
    "    # Set the bad channels in the current raw data\n",
    "    raw.info['bads'] = bad_channels_for_interpolation\n",
    "    n_bad = len(bad_channels_for_interpolation)\n",
    "    \n",
    "    print(f\"üìç Interpolating {n_bad} bad channels: {bad_channels_for_interpolation}\")\n",
    "    \n",
    "    try:\n",
    "        # Interpolate bad channels using spherical splines\n",
    "        raw.interpolate_bads(reset_bads=True, verbose=False)\n",
    "        print(f\"‚úÖ Successfully interpolated {n_bad} channels\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Interpolation failed: {e}\")\n",
    "        print(\"This usually means channel positions are missing from montage\")\n",
    "        # Clear the bad channels list if interpolation failed\n",
    "        raw.info['bads'] = []\n",
    "        \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No bad channels to interpolate\")\n",
    "\n",
    "# Summary\n",
    "n_remaining_bad = len(raw.info['bads'])\n",
    "print(f\"üìä Channel status: {len(raw.ch_names)} total, {n_remaining_bad} still marked as bad\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After Interpolation'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_interp = compute_snr(raw)\n",
    "processing_log['After Interpolation'] = snr_after_interp\n",
    "print_snr_summary(snr_after_interp, \"After Channel Interpolation\")\n",
    "\n",
    "# Plot before/after comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After ICA'], raw_versions['After Interpolation']], \n",
    "    ['Before Interpolation', 'After Interpolation'],\n",
    "    \"Power Spectral Density: Channel Interpolation Effect\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asr",
   "metadata": {},
   "source": [
    "### 5.7 Bad Time Segments Removal (Artifact Subspace Reconstruction)\n",
    "\n",
    "**Purpose**: Automatically detect and correct brief periods of extreme artifacts that affect multiple channels simultaneously.\n",
    "\n",
    "**Why needed**: Even after other cleaning steps, occasional periods of extreme artifacts can remain (sudden movements, cable bumps, amplifier saturation). These brief but severe artifacts can distort statistical analyses and connectivity measures.\n",
    "\n",
    "**Method**: ASR learns the 'normal' signal patterns from clean calibration data, then identifies and reconstructs time periods where the signal deviates beyond a statistical threshold, effectively removing transient artifacts while preserving normal neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asr-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ‚ö° Remove Bad Time Segments (ASR)\n",
    "\n",
    "print(\"‚ö° Applying Artifact Subspace Reconstruction...\")\n",
    "\n",
    "try:\n",
    "    from meegkit.asr import ASR\n",
    "    \n",
    "    # Get good EEG channels only (exclude bad channels)\n",
    "    picks_eeg_good = mne.pick_types(raw.info, eeg=True, eog=False, exclude='bads')\n",
    "    \n",
    "    if len(picks_eeg_good) == 0:\n",
    "        raise ValueError(\"No good EEG channels available for ASR\")\n",
    "    \n",
    "    eeg_data = raw.get_data(picks=picks_eeg_good)\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # ASR parameters\n",
    "    asr_cutoff = 5  # Standard deviation cutoff\n",
    "    train_duration = min(30, raw.times[-1])  # Use first 30s or less for training\n",
    "    train_samples = int(train_duration * sfreq)\n",
    "    \n",
    "    print(f\"üîß ASR cutoff: {asr_cutoff}œÉ, training: {train_duration:.1f}s on {len(picks_eeg_good)} channels\")\n",
    "    \n",
    "    # Fit ASR on clean training data\n",
    "    asr = ASR(sfreq=sfreq, cutoff=asr_cutoff)\n",
    "    train_data = eeg_data[:, :train_samples]\n",
    "    asr.fit(train_data)\n",
    "    \n",
    "    # Transform the entire EEG dataset\n",
    "    cleaned_data = asr.transform(eeg_data)\n",
    "    \n",
    "    # Calculate reconstruction percentage\n",
    "    reconstruction_pct = np.mean(np.var(eeg_data - cleaned_data, axis=1) / np.var(eeg_data, axis=1)) * 100\n",
    "    \n",
    "    # Update only the good EEG channels in raw data\n",
    "    raw._data[picks_eeg_good] = cleaned_data\n",
    "    \n",
    "    print(f\"‚úÖ ASR applied - {reconstruction_pct:.1f}% of signal reconstructed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ASR failed: {e}\")\n",
    "    print(\"Continuing without ASR...\")\n",
    "\n",
    "# Store results\n",
    "raw_versions['After ASR'] = raw.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_asr = compute_snr(raw)\n",
    "processing_log['After ASR'] = snr_after_asr\n",
    "print_snr_summary(snr_after_asr, \"After ASR\")\n",
    "\n",
    "# Plot before/after comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Interpolation'], raw_versions['After ASR']], \n",
    "    ['Before ASR', 'After ASR'],\n",
    "    \"Power Spectral Density: ASR Effect\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-assessment",
   "metadata": {},
   "source": [
    "## 6. Final Quality Assessment\n",
    "\n",
    "**Purpose**: Evaluate the overall effectiveness of the preprocessing pipeline and document improvements.\n",
    "\n",
    "**Why needed**: It's crucial to verify that preprocessing actually improved data quality rather than inadvertently removing important neural signals. Quantitative metrics provide objective evidence of improvement and help optimize preprocessing parameters.\n",
    "\n",
    "**Methods**: Compare SNR across frequency bands before and after processing, visualize PSD changes, and generate comprehensive quality reports.\n",
    "\n",
    "Let's examine the overall improvement in data quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-quality-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìà Final Quality Assessment\n",
    "\n",
    "print(\"üìà Final Quality Assessment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get the final processing step that was completed\n",
    "final_step_names = list(raw_versions.keys())\n",
    "final_step = final_step_names[-1]  # Last completed step\n",
    "final_raw = raw_versions[final_step]\n",
    "\n",
    "print(f\"Final processing step: {final_step}\")\n",
    "\n",
    "# Plot processing summary showing SNR progression\n",
    "plot_processing_summary(processing_log)\n",
    "\n",
    "# Final comparison: Original vs Final processed data\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['Original'], final_raw], \n",
    "    ['Original Data', 'Fully Processed'],\n",
    "    f\"Final Comparison: Original vs {final_step}\"\n",
    ")\n",
    "\n",
    "# SNR improvement summary\n",
    "print(\"\\nüéØ SNR Improvement Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "original_snr = processing_log['Original']\n",
    "final_snr = processing_log[final_step]\n",
    "\n",
    "for band in ['delta', 'theta', 'alpha', 'beta', 'gamma']:\n",
    "    original_val = original_snr[band]['mean_snr']\n",
    "    final_val = final_snr[band]['mean_snr']\n",
    "    improvement = final_val - original_val\n",
    "    \n",
    "    status = \"‚ÜóÔ∏è\" if improvement > 0 else \"‚ÜòÔ∏è\" if improvement < 0 else \"‚Üí\"\n",
    "    print(f\"{band.capitalize():>8}: {original_val:6.2f} ‚Üí {final_val:6.2f} dB ({improvement:+5.2f} dB) {status}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Final data summary\n",
    "print(\"\\nüìä Final Data Summary:\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Duration: {raw.times[-1]:.1f} seconds\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Sampling rate: {raw.info['sfreq']:.0f} Hz\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Channels: {len(raw.ch_names)} EEG\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Bad channels processed: {len(bad_channels_for_interpolation) if 'bad_channels_for_interpolation' in locals() else 0}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Final step completed: {final_step}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Pipeline completed successfully! ‚úÖ\")\n",
    "\n",
    "# Processing steps completed\n",
    "print(f\"\\nüîÑ Processing Steps Completed:\")\n",
    "for i, step in enumerate(final_step_names, 1):\n",
    "    print(f\"   {i}. {step}\")\n",
    "\n",
    "print(f\"\\nüéâ EEG preprocessing pipeline completed!\")\n",
    "print(f\"Your cleaned EEG data is ready for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving",
   "metadata": {},
   "source": [
    "## 7. Saving Results\n",
    "\n",
    "**Purpose**: Export cleaned data in multiple formats and generate comprehensive documentation of the preprocessing workflow.\n",
    "\n",
    "**Why needed**: Different analysis software requires different file formats. Documentation ensures reproducibility and helps track what preprocessing steps were applied. Quality metrics provide evidence of data improvement for publications.\n",
    "\n",
    "**Methods**: Save in common EEG formats (BrainVision, EEGLAB, EDF), generate HTML reports with MNE, and export quantitative quality metrics as CSV files.\n",
    "\n",
    "Save the cleaned data and generate a processing report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üíæ Save Cleaned Data\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üíæ Saving cleaned EEG data...\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('cleaneeg_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Get input file information (must exist from data loading)\n",
    "if 'eeg_file' not in locals():\n",
    "    print(\"‚ùå No input file information found!\")\n",
    "    raise ValueError(\"Cannot determine input file - please check data loading step\")\n",
    "\n",
    "input_file = eeg_file\n",
    "input_format = input_file.suffix\n",
    "print(f\"üìÇ Input file: {input_file.name} (format: {input_format})\")\n",
    "\n",
    "# Create output filename with same base name as input\n",
    "output_file = output_dir / f\"{input_file.stem}_clean{input_file.suffix}\"\n",
    "\n",
    "# Save cleaned data\n",
    "try:\n",
    "    if input_format == '.fif':\n",
    "        raw.save(output_file, overwrite=True, verbose=False)\n",
    "    else:\n",
    "        mne.export.export_raw(output_file, raw, fmt='auto', overwrite=True, verbose=False)\n",
    "    \n",
    "    print(f\"‚úÖ Cleaned data saved: {output_file.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to save data: {e}\")\n",
    "    output_file = None\n",
    "\n",
    "# Create simple before/after comparison report\n",
    "print(\"üìä Creating comparison report...\")\n",
    "\n",
    "try:\n",
    "    # Get original and final data\n",
    "    original_raw = raw_versions['Original']\n",
    "    final_step = list(raw_versions.keys())[-1]\n",
    "    final_raw = raw_versions[final_step]\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('EEG Processing Comparison: Original vs Cleaned', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Original PSD\n",
    "    original_psd = original_raw.compute_psd(fmax=50, verbose=False)\n",
    "    original_psd.plot(axes=ax1, show=False, spatial_colors=False, average=True)\n",
    "    ax1.set_title('Original Data - Power Spectral Density')\n",
    "    ax1.set_xlabel('Frequency (Hz)')\n",
    "    ax1.set_ylabel('Power (dB)')\n",
    "    \n",
    "    # Cleaned PSD  \n",
    "    final_psd = final_raw.compute_psd(fmax=50, verbose=False)\n",
    "    final_psd.plot(axes=ax2, show=False, spatial_colors=False, average=True)\n",
    "    ax2.set_title('Cleaned Data - Power Spectral Density')\n",
    "    ax2.set_xlabel('Frequency (Hz)')\n",
    "    ax2.set_ylabel('Power (dB)')\n",
    "    \n",
    "    # SNR comparison by frequency band\n",
    "    original_snr = processing_log['Original']\n",
    "    final_snr = processing_log[final_step]\n",
    "    \n",
    "    bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    original_values = [original_snr[band]['mean_snr'] for band in bands]\n",
    "    final_values = [final_snr[band]['mean_snr'] for band in bands]\n",
    "    \n",
    "    x = range(len(bands))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax3.bar([i - width/2 for i in x], original_values, width, label='Original', alpha=0.7)\n",
    "    ax3.bar([i + width/2 for i in x], final_values, width, label='Cleaned', alpha=0.7)\n",
    "    ax3.set_xlabel('Frequency Band')\n",
    "    ax3.set_ylabel('SNR (dB)')\n",
    "    ax3.set_title('Signal-to-Noise Ratio by Frequency Band')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels([b.capitalize() for b in bands])\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # SNR improvement\n",
    "    improvements = [final_values[i] - original_values[i] for i in range(len(bands))]\n",
    "    colors = ['green' if imp > 0 else 'red' if imp < 0 else 'gray' for imp in improvements]\n",
    "    \n",
    "    ax4.bar(x, improvements, color=colors, alpha=0.7)\n",
    "    ax4.set_xlabel('Frequency Band')\n",
    "    ax4.set_ylabel('SNR Improvement (dB)')\n",
    "    ax4.set_title('SNR Improvement After Processing')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels([b.capitalize() for b in bands])\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save comparison plot with same base name as input file\n",
    "    report_file = output_dir / f\"{input_file.stem}_comparison.png\"\n",
    "    plt.savefig(report_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Comparison report saved: {report_file.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create report: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüéâ Processing completed!\")\n",
    "print(f\"üìÅ Output folder: {output_dir.absolute()}\")\n",
    "if output_file:\n",
    "    print(f\"üìÑ Cleaned data: {output_file.name}\")\n",
    "    print(f\"üìä Comparison: {input_file.stem}_comparison.png\")\n",
    "\n",
    "print(f\"\\n‚úÖ Your cleaned EEG data is ready for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "üéâ **Congratulations!** You have successfully completed the CleanEEG preprocessing pipeline.\n",
    "\n",
    "### What we accomplished:\n",
    "\n",
    "1. **Loaded and inspected** your EEG data\n",
    "2. **Applied comprehensive preprocessing** following the DISCOVER-EEG framework:\n",
    "   - Line noise removal using Denoising Source Separation\n",
    "   - Bandpass filtering to remove slow drifts and high-frequency noise\n",
    "   - Downsampling for computational efficiency\n",
    "   - Automatic bad channel detection using PREP pipeline\n",
    "   - Independent Component Analysis with automatic classification\n",
    "   - Bad channel interpolation\n",
    "   - Bad time segment removal using Artifact Subspace Reconstruction\n",
    "\n",
    "3. **Monitored data quality** throughout the pipeline using SNR metrics\n",
    "4. **Saved cleaned data** in multiple formats for further analysis\n",
    "5. **Generated comprehensive reports** documenting the preprocessing steps\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "Your cleaned EEG data is now ready for:\n",
    "- **Spectral analysis** (power spectral density, frequency band analysis)\n",
    "- **Connectivity analysis** (coherence, phase-amplitude coupling)\n",
    "- **Event-related potential analysis** (if you have event markers)\n",
    "- **Machine learning applications** (classification, regression)\n",
    "- **Source localization** (if you have a forward model)\n",
    "\n",
    "### Tips for further analysis:\n",
    "\n",
    "- The cleaned data maintains the original channel structure and timing\n",
    "- All preprocessing steps are documented in the generated reports\n",
    "- SNR improvements indicate the effectiveness of each preprocessing step\n",
    "- Consider the specific requirements of your analysis when choosing output formats\n",
    "\n",
    "**Happy analyzing!** üß†‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9ea81-1a86-4a4e-ba30-b1c5a332dce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
