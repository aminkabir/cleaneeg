{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be58c31a-9193-4030-816f-cf2cfb6d58da",
   "metadata": {},
   "source": [
    "# CleanEEG: Automated Resting-State EEG Preprocessing Tutorial\n",
    "This tutorial demonstrates the complete CleanEEG preprocessing pipeline using MNE-Python and complementary libraries. Based on the DISCOVER-EEG framework, it covers all preprocessing steps with quality assessment metrics including Signal-to-Noise Ratio (SNR) and Power Spectral Density (PSD) visualization after each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table-of-contents",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Installation and Setup](#installation)\n",
    "2. [Quality Assessment Functions](#quality-functions)\n",
    "3. [Loading EEG Data](#loading-data)\n",
    "4. [Channel Montage Setup](#montage-setup)\n",
    "5. [Preprocessing Pipeline](#preprocessing-pipeline)\n",
    "   - [Line Noise Removal (DSS)](#line-noise)\n",
    "   - [Bandpass Filter](#bandpass-filter)\n",
    "   - [Downsample Data](#downsample)\n",
    "   - [Bad Channel Rejection (PREP)](#bad-channels)\n",
    "   - [EOG Artifact Removal](#eog-removal)\n",
    "   - [Independent Component Analysis (ICA)](#ica)\n",
    "   - [Bad Channel Interpolation](#interpolation)\n",
    "   - [Bad Time Segments Removal (ASR)](#asr)\n",
    "6. [Final Quality Assessment](#final-assessment)\n",
    "7. [Saving Results](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a6625-e62b-40e5-8ea4-9fc809f650d7",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup {#installation}\n",
    "\n",
    "### Option 1: Using Conda Environment (Recommended)\n",
    "\n",
    "Create a conda environment with all dependencies:\n",
    "\n",
    "```bash\n",
    "# Create environment from the provided environment.yml\n",
    "conda env create -f environment.yml\n",
    "conda activate cleaneeg\n",
    "```\n",
    "\n",
    "### Option 2: Using Pip Environment\n",
    "\n",
    "Create a virtual environment and install dependencies:\n",
    "\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python -m venv cleaneeg_env\n",
    "source cleaneeg_env/bin/activate  # On Windows: cleaneeg_env\\Scripts\\activate\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Option 3: Install in Current Environment (Jupyter/Colab)\n",
    "\n",
    "If you're running this in Jupyter or Google Colab, you can install packages directly:"
   ]
  },
  {
   "cell_type": "code",
   "id": "97ae8259-43fd-49dd-8d8b-624575c2042b",
   "metadata": {},
   "source": [
    "# Install required packages for EEG processing and visualization\n",
    "!pip install mne==1.5.0           # Core package for EEG/MEG data analysis\n",
    "!pip install pyprep>=0.4.0        # For automatic bad channel detection\n",
    "!pip install meegkit>=0.1.5       # For advanced denoising methods (DSS, ASR)\n",
    "!pip install mne-icalabel==0.5.0  # For automatic classification of ICA components\n",
    "!pip install matplotlib>=3.6.0    # For visualization\n",
    "!pip install numpy==1.26.4        # For numerical operations\n",
    "!pip install scipy>=1.10.0        # For scientific computing\n",
    "!pip install pandas>=1.5.0        # For data handling\n",
    "!pip install pybv>=0.7.0          # For BrainVision file support\n",
    "!pip install eeglabio>=0.0.2      # For EEGLAB file support\n",
    "!pip install edfio>=0.1.0         # For EDF file support\n",
    "!pip install EDFlib-Python>=1.0.8 # For EDF+ file support\n",
    "!pip install h5py>=3.7.0          # For HDF5 file support\n",
    "!pip install tqdm                 # For progress bars (sample data download)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "verify-installation",
   "metadata": {},
   "source": [
    "### Verify Installation\n",
    "Let's check that all required packages are installed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "id": "verify-packages",
   "metadata": {},
   "source": [
    "# Verify installation of key packages\n",
    "required_packages = {\n",
    "    'mne': '1.5.0',\n",
    "    'numpy': '1.26.4',\n",
    "    'scipy': '1.10.0',\n",
    "    'matplotlib': '3.6.0',\n",
    "    'pandas': '1.5.0',\n",
    "    'pyprep': '0.4.0',\n",
    "    'meegkit': '0.1.5',\n",
    "    'mne_icalabel': '0.5.0'\n",
    "}\n",
    "\n",
    "print(\"üîç Verifying package installations...\\n\")\n",
    "\n",
    "installation_status = {}\n",
    "for package, min_version in required_packages.items():\n",
    "    try:\n",
    "        if package == 'mne_icalabel':\n",
    "            import mne_icalabel\n",
    "            version = mne_icalabel.__version__\n",
    "        else:\n",
    "            module = __import__(package)\n",
    "            version = getattr(module, '__version__', 'Unknown')\n",
    "        \n",
    "        installation_status[package] = {'installed': True, 'version': version}\n",
    "        print(f\"‚úÖ {package:12} v{version}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        installation_status[package] = {'installed': False, 'version': None}\n",
    "        print(f\"‚ùå {package:12} - NOT INSTALLED\")\n",
    "    except Exception as e:\n",
    "        installation_status[package] = {'installed': False, 'version': None}\n",
    "        print(f\"‚ö†Ô∏è  {package:12} - ERROR: {e}\")\n",
    "\n",
    "# Check installation completeness\n",
    "installed_packages = sum(1 for status in installation_status.values() if status['installed'])\n",
    "total_packages = len(required_packages)\n",
    "\n",
    "print(f\"\\nüìä Installation Summary: {installed_packages}/{total_packages} packages installed\")\n",
    "\n",
    "if installed_packages == total_packages:\n",
    "    print(\"üéâ All packages installed successfully! Ready to proceed.\")\n",
    "elif installed_packages >= total_packages * 0.8:  # 80% threshold\n",
    "    print(\"‚ö†Ô∏è  Most packages installed. Some optional features may not work.\")\n",
    "else:\n",
    "    print(\"‚ùå Many packages missing. Please check your installation.\")\n",
    "    print(\"   Consider reinstalling with: pip install -r requirements.txt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "# Import all necessary libraries\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import ftplib\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set MNE logging level\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "sample-data-section",
   "metadata": {},
   "source": [
    "### Sample Data Download Function\n",
    "If you don't have your own EEG data, we'll implement a function to download sample resting-state EEG data:"
   ]
  },
  {
   "cell_type": "code",
   "id": "sample-data-function",
   "metadata": {},
   "source": [
    "# Sample data download function implementation\n",
    "import ftplib\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def is_dir(ftp: ftplib.FTP, path: str) -> bool:\n",
    "    \"\"\"Check if a path is a directory on the FTP server.\"\"\"\n",
    "    cwd = ftp.pwd()\n",
    "    try:\n",
    "        ftp.cwd(path)\n",
    "        ftp.cwd(cwd)\n",
    "        return True\n",
    "    except ftplib.error_perm:\n",
    "        return False\n",
    "\n",
    "def download_remote(ftp: ftplib.FTP, remote_dir: str, local_dir: Path):\n",
    "    \"\"\"Recursively download files from FTP server.\"\"\"\n",
    "    local_dir.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        ftp.cwd(remote_dir)\n",
    "    except ftplib.error_perm:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        entries = list(ftp.mlsd())\n",
    "    except (ftplib.error_perm, AttributeError):\n",
    "        names = ftp.nlst()\n",
    "        entries = [(name, {'type': 'dir' if is_dir(ftp, f\"{remote_dir}/{name}\") else 'file'})\n",
    "                   for name in names]\n",
    "    \n",
    "    for name, info in tqdm(entries, desc=f\"Scanning {Path(remote_dir).name}\", leave=False):\n",
    "        rpath = f\"{remote_dir}/{name}\"\n",
    "        lpath = local_dir / name\n",
    "        \n",
    "        if info.get('type') == 'dir':\n",
    "            download_remote(ftp, rpath, lpath)\n",
    "        else:\n",
    "            if not lpath.exists():  # Skip if file already exists\n",
    "                try:\n",
    "                    with open(lpath, 'wb') as f:\n",
    "                        ftp.retrbinary(f\"RETR {rpath}\", f.write)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to download {rpath}: {e}\")\n",
    "            else:\n",
    "                print(f\"üìÅ File already exists: {lpath.name}\")\n",
    "\n",
    "def download_sample_data(ftp_host: str,\n",
    "                         ftp_base: str,\n",
    "                         local_base: Path,\n",
    "                         num_subjects: int = 1):\n",
    "    \"\"\"\n",
    "    Download sample EEG data from FTP server.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ftp_host : str\n",
    "        FTP server hostname\n",
    "    ftp_base : str\n",
    "        Base directory on FTP server\n",
    "    local_base : Path\n",
    "        Local directory to save data\n",
    "    num_subjects : int\n",
    "        Number of subjects to download\n",
    "    \"\"\"\n",
    "    print(f\"üåê Connecting to {ftp_host}...\")\n",
    "    \n",
    "    try:\n",
    "        ftp = ftplib.FTP(ftp_host)\n",
    "        ftp.login()\n",
    "        ftp.cwd(ftp_base)\n",
    "        \n",
    "        subjects = ftp.nlst()\n",
    "        if len(subjects) < num_subjects:\n",
    "            raise ValueError(f\"Found only {len(subjects)} subjects, asked for {num_subjects}\")\n",
    "        \n",
    "        chosen = random.sample(subjects, num_subjects)\n",
    "        print(f\"üì• Downloading {num_subjects} random subject(s): {chosen}\\n\")\n",
    "        \n",
    "        for subj in tqdm(chosen, desc=\"Subjects\"):\n",
    "            download_remote(ftp, f\"{ftp_base}/{subj}\", local_base / subj)\n",
    "        \n",
    "        ftp.quit()\n",
    "        print(f\"\\n‚úÖ Download complete. Data is in: {local_base.resolve()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        print(\"   Will use MNE sample data instead...\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Sample data download functions loaded!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "download-sample-data",
   "metadata": {},
   "source": [
    "### Download Sample Data (Optional)\n",
    "If you don't have your own resting-state EEG data, you can download sample data from public repositories:"
   ]
  },
  {
   "cell_type": "code",
   "id": "192762da-8650-4249-a69d-a91a6fa6c783",
   "metadata": {},
   "source": [
    "# Download sample EEG data\n",
    "sample_data_downloaded = False\n",
    "sample_data_path = Path('sample_data')\n",
    "\n",
    "print(\"üîç Checking for existing sample data...\")\n",
    "if sample_data_path.exists() and any(sample_data_path.iterdir()):\n",
    "    print(f\"‚úÖ Found existing data in {sample_data_path}\")\n",
    "    sample_data_downloaded = True\n",
    "else:\n",
    "    print(\"üì• No existing data found. Attempting to download sample data...\")\n",
    "    \n",
    "    # Try to download from MPI-Leipzig LEMON dataset\n",
    "    # This dataset contains high-quality resting-state EEG recordings\n",
    "    try:\n",
    "        sample_data_downloaded = download_sample_data(\n",
    "            ftp_host='ftp.gwdg.de',\n",
    "            ftp_base='/pub/misc/MPI-Leipzig_Mind-Brain-Body-LEMON/EEG_MPILMBB_LEMON/EEG_Raw_BIDS_ID',\n",
    "            local_base=sample_data_path,\n",
    "            num_subjects=1  # Download just one subject for this tutorial\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è FTP download failed: {e}\")\n",
    "        sample_data_downloaded = False\n",
    "\n",
    "# Fallback to MNE sample data if download fails\n",
    "if not sample_data_downloaded:\n",
    "    print(\"\\nüîÑ Falling back to MNE sample data...\")\n",
    "    try:\n",
    "        # Use MNE's built-in sample dataset\n",
    "        import mne\n",
    "        sample_data_folder = mne.datasets.sample.data_path()\n",
    "        sample_data_path = sample_data_folder / 'MEG' / 'sample'\n",
    "        print(f\"‚úÖ Will use MNE sample data from: {sample_data_path}\")\n",
    "        sample_data_downloaded = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå MNE sample data also failed: {e}\")\n",
    "        print(\"   Please provide your own EEG data file path in the next section.\")\n",
    "\n",
    "print(f\"\\nüìä Sample data status: {'Available' if sample_data_downloaded else 'Not available'}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "quality-functions",
   "metadata": {},
   "source": [
    "## 2. Quality Assessment Functions {#quality-functions}\n",
    "\n",
    "**Purpose**: Monitor and quantify data quality improvements throughout the preprocessing pipeline.\n",
    "\n",
    "**Why needed**: Preprocessing should improve signal quality, but it's important to verify this objectively. Signal-to-Noise Ratio (SNR) and Power Spectral Density (PSD) provide quantitative metrics to ensure each step is helping rather than hurting data quality.\n",
    "\n",
    "**Methods**: \n",
    "- **SNR calculation**: Compares signal power in neural frequency bands to noise estimates\n",
    "- **PSD visualization**: Shows how preprocessing affects the frequency content of signals\n",
    "- **Progress tracking**: Documents quality changes after each preprocessing step\n",
    "\n",
    "These functions will help us track data quality throughout the preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "id": "quality-assessment-functions",
   "metadata": {},
   "source": [
    "def compute_snr(raw, freq_bands=None, method='rms'):\n",
    "    \"\"\"\n",
    "    Compute Signal-to-Noise Ratio for EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw : mne.io.Raw\n",
    "        The EEG data\n",
    "    freq_bands : dict\n",
    "        Dictionary of frequency bands to analyze\n",
    "    method : str\n",
    "        Method for SNR calculation ('rms' or 'spectral')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    snr_results : dict\n",
    "        SNR values for different frequency bands\n",
    "    \"\"\"\n",
    "    if freq_bands is None:\n",
    "        freq_bands = {\n",
    "            'delta': (1, 4),\n",
    "            'theta': (4, 8), \n",
    "            'alpha': (8, 13),\n",
    "            'beta': (13, 30),\n",
    "            'gamma': (30, 100)\n",
    "        }\n",
    "    \n",
    "    # Get data and sampling frequency\n",
    "    data = raw.get_data()\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    snr_results = {}\n",
    "    \n",
    "    if method == 'spectral':\n",
    "        # Compute PSD\n",
    "        freqs, psd = signal.welch(data, sfreq, nperseg=int(2*sfreq))\n",
    "        \n",
    "        for band_name, (low_freq, high_freq) in freq_bands.items():\n",
    "            # Find frequency indices\n",
    "            freq_mask = (freqs >= low_freq) & (freqs <= high_freq)\n",
    "            \n",
    "            # Signal power in the band\n",
    "            signal_power = np.mean(psd[:, freq_mask], axis=1)\n",
    "            \n",
    "            # Noise estimation (neighboring frequencies)\n",
    "            noise_low = max(0, low_freq - 2)\n",
    "            noise_high = min(freqs[-1], high_freq + 2)\n",
    "            noise_mask = ((freqs >= noise_low) & (freqs < low_freq)) | \\\n",
    "                        ((freqs > high_freq) & (freqs <= noise_high))\n",
    "            \n",
    "            if np.any(noise_mask):\n",
    "                noise_power = np.mean(psd[:, noise_mask], axis=1)\n",
    "                snr = 10 * np.log10(signal_power / (noise_power + 1e-10))\n",
    "            else:\n",
    "                snr = np.full(len(raw.ch_names), np.nan)\n",
    "            \n",
    "            snr_results[band_name] = {\n",
    "                'mean_snr': np.nanmean(snr),\n",
    "                'std_snr': np.nanstd(snr),\n",
    "                'channel_snr': snr\n",
    "            }\n",
    "    \n",
    "    else:  # RMS method\n",
    "        for band_name, (low_freq, high_freq) in freq_bands.items():\n",
    "            # Filter data to frequency band\n",
    "            raw_filtered = raw.copy().filter(low_freq, high_freq, verbose=False)\n",
    "            filtered_data = raw_filtered.get_data()\n",
    "            \n",
    "            # RMS of signal\n",
    "            signal_rms = np.sqrt(np.mean(filtered_data**2, axis=1))\n",
    "            \n",
    "            # Estimate noise from high frequencies (above 80 Hz)\n",
    "            if raw.info['sfreq'] > 160:  # Ensure we can filter above 80 Hz\n",
    "                raw_noise = raw.copy().filter(80, None, verbose=False)\n",
    "                noise_data = raw_noise.get_data()\n",
    "                noise_rms = np.sqrt(np.mean(noise_data**2, axis=1))\n",
    "                snr = 20 * np.log10(signal_rms / (noise_rms + 1e-10))\n",
    "            else:\n",
    "                # Use standard deviation as noise estimate\n",
    "                noise_std = np.std(filtered_data, axis=1)\n",
    "                snr = 20 * np.log10(signal_rms / (noise_std + 1e-10))\n",
    "            \n",
    "            snr_results[band_name] = {\n",
    "                'mean_snr': np.mean(snr),\n",
    "                'std_snr': np.std(snr),\n",
    "                'channel_snr': snr\n",
    "            }\n",
    "    \n",
    "    return snr_results\n",
    "\n",
    "def plot_psd_comparison(raw_list, labels, title=\"Power Spectral Density Comparison\", fmax=80):\n",
    "    \"\"\"\n",
    "    Plot PSD comparison for multiple raw objects.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_list : list\n",
    "        List of mne.io.Raw objects\n",
    "    labels : list\n",
    "        Labels for each raw object\n",
    "    title : str\n",
    "        Plot title\n",
    "    fmax : float\n",
    "        Maximum frequency to plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Red for before, Blue for after\n",
    "    colors = ['red', 'blue'][:len(raw_list)]\n",
    "    \n",
    "    for i, (raw, label, color) in enumerate(zip(raw_list, labels, colors)):\n",
    "        # Compute PSD\n",
    "        psd = raw.compute_psd(fmax=fmax, verbose=False)\n",
    "        \n",
    "        # Plot average across channels\n",
    "        freqs = psd.freqs\n",
    "        psd_data = psd.get_data()\n",
    "        mean_psd = np.mean(psd_data, axis=0)\n",
    "        \n",
    "        ax.semilogy(freqs, mean_psd, label=label, color=color, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Power Spectral Density (V¬≤/Hz)')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_snr_summary(snr_results, step_name):\n",
    "    \"\"\"\n",
    "    Print a formatted summary of SNR results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä SNR Summary - {step_name}:\")\n",
    "    print(\"=\" * 50)\n",
    "    for band, results in snr_results.items():\n",
    "        print(f\"{band.capitalize():>8}: {results['mean_snr']:6.2f} ¬± {results['std_snr']:5.2f} dB\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def plot_processing_summary(processing_log):\n",
    "    \"\"\"\n",
    "    Plot a summary of SNR changes throughout processing.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    steps = list(processing_log.keys())\n",
    "    \n",
    "    for i, band in enumerate(bands):\n",
    "        if i < len(axes):\n",
    "            snr_values = [processing_log[step][band]['mean_snr'] for step in steps]\n",
    "            axes[i].plot(range(len(steps)), snr_values, 'o-', linewidth=2, markersize=8)\n",
    "            axes[i].set_title(f'{band.capitalize()} Band SNR')\n",
    "            axes[i].set_ylabel('SNR (dB)')\n",
    "            axes[i].set_xticks(range(len(steps)))\n",
    "            axes[i].set_xticklabels(steps, rotation=45, ha='right')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove the last subplot if we have 6 subplots but only 5 bands\n",
    "    if len(bands) < len(axes):\n",
    "        fig.delaxes(axes[-1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Quality assessment functions loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df1f7e84-085c-4205-b37f-e0a818030ba1",
   "metadata": {},
   "source": [
    "## 3. Loading EEG Data {#loading-data}\n",
    "Load your EEG data from various formats supported by MNE-Python."
   ]
  },
  {
   "cell_type": "code",
   "id": "c9b927d0-cf4b-49d5-8b23-97b2d445ea26",
   "metadata": {},
   "source": [
    "# Define the path to your EEG data\n",
    "# You can either:\n",
    "# 1. Use the downloaded sample data (if available)\n",
    "# 2. Update this path to point to your own EEG files\n",
    "# 3. Use MNE sample data as fallback\n",
    "\n",
    "data_path = None\n",
    "user_data_path = Path('your_eeg_data')  # Change this to your data directory\n",
    "\n",
    "# Check for user data first\n",
    "if user_data_path.exists() and user_data_path != Path('your_eeg_data'):\n",
    "    data_path = user_data_path\n",
    "    print(f\"üìÅ Using user-specified data path: {data_path}\")\n",
    "elif sample_data_downloaded:\n",
    "    data_path = sample_data_path\n",
    "    print(f\"üìÅ Using downloaded sample data: {data_path}\")\n",
    "\n",
    "# List of valid EEG file extensions that MNE can read\n",
    "valid_eeg_formats = [\".vhdr\", \".edf\", \".bdf\", \".gdf\", \".cnt\", \".egi\", \n",
    "                    \".mff\", \".set\", \".fif\", \".data\", \".nxe\", \".lay\"]\n",
    "\n",
    "# Find EEG files automatically\n",
    "eeg_files = []\n",
    "if data_path and data_path.exists():\n",
    "    for ext in valid_eeg_formats:\n",
    "        eeg_files.extend(list(data_path.rglob(f\"*{ext}\")))\n",
    "\n",
    "if not eeg_files:\n",
    "    print(\"‚ö†Ô∏è No EEG files found in specified directories.\")\n",
    "    print(\"üîÑ Using MNE sample data as fallback...\")\n",
    "    \n",
    "    # Use MNE sample data as fallback\n",
    "    try:\n",
    "        sample_data_folder = mne.datasets.sample.data_path()\n",
    "        sample_data_raw_file = sample_data_folder / 'MEG' / 'sample' / 'sample_audvis_filt-0-40_raw.fif'\n",
    "        raw = mne.io.read_raw_fif(sample_data_raw_file, preload=True)\n",
    "        \n",
    "        # Pick only EEG channels for this tutorial\n",
    "        raw.pick('eeg')\n",
    "        \n",
    "        print(f\"‚úÖ Using MNE sample EEG data: {len(raw.ch_names)} EEG channels\")\n",
    "        data_source = \"MNE Sample Data\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load MNE sample data: {e}\")\n",
    "        print(\"   Please specify a valid EEG data path in the 'user_data_path' variable above.\")\n",
    "        raise FileNotFoundError(\"No EEG data available for processing\")\nelse:\n",
    "    # Use the first EEG file found\n",
    "    eeg_path = eeg_files[0]\n",
    "    print(f\"üìÅ Loading {eeg_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Read the EEG data\n",
    "        raw = mne.io.read_raw(eeg_path, preload=True)\n",
    "        \n",
    "        # Pick EEG channels only (if other channel types exist)\n",
    "        if len(mne.pick_types(raw.info, eeg=True)) > 0:\n",
    "            raw.pick('eeg')\n",
    "        \n",
    "        data_source = f\"External File: {eeg_path.name}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {eeg_path}: {e}\")\n",
    "        print(\"   Trying MNE sample data as fallback...\")\n",
    "        \n",
    "        # Fallback to MNE sample data\n",
    "        sample_data_folder = mne.datasets.sample.data_path()\n",
    "        sample_data_raw_file = sample_data_folder / 'MEG' / 'sample' / 'sample_audvis_filt-0-40_raw.fif'\n",
    "        raw = mne.io.read_raw_fif(sample_data_raw_file, preload=True)\n",
    "        raw.pick('eeg')\n",
    "        data_source = \"MNE Sample Data (fallback)\"\n",
    "\n",
    "# Print basic information about the loaded data\n",
    "print(\"\\nüìã EEG Data Information:\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Data source: {data_source}\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Sampling rate: {raw.info['sfreq']} Hz\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Duration: {raw.times[-1]:.1f} seconds\")\n",
    "print(f\"‚îú‚îÄ‚îÄ Number of EEG channels: {len(raw.ch_names)}\")\n",
    "print(f\"‚îî‚îÄ‚îÄ Channel names: {raw.ch_names[:10]}{'...' if len(raw.ch_names) > 10 else ''}\")\n",
    "\n",
    "# Create processing log to track quality metrics\n",
    "processing_log = {}\n",
    "raw_versions = {'Original': raw.copy()}\n",
    "\n",
    "# Initial quality assessment\n",
    "print(\"\\nüîç Computing initial data quality...\")\n",
    "initial_snr = compute_snr(raw, method='spectral')\n",
    "processing_log['Original'] = initial_snr\n",
    "print_snr_summary(initial_snr, \"Original Data\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad106c8c-b907-4f86-8e87-8b2b406578fe",
   "metadata": {},
   "source": [
    "## 4. Channel Montage Setup {#montage-setup}\n",
    "\n",
    "**Purpose**: Assign 3D spatial coordinates to each EEG electrode for spatial analyses and visualizations.\n",
    "\n",
    "**Why needed**: Many preprocessing steps (bad channel detection, interpolation) and analyses (source localization, connectivity) require knowing where each electrode is positioned on the scalp. Without spatial information, we can't determine which channels are neighbors or create topographic maps.\n",
    "\n",
    "**Method**: Match electrode names to standard montage templates (10-20, 10-05, etc.) that define precise 3D coordinates for each electrode position."
   ]
  },
  {
   "cell_type": "code",
   "id": "f4fad717-175c-4f4f-a646-fa32503c21cb",
   "metadata": {},
   "source": [
    "# Enhanced Channel Type Setup and EEG Processing\n",
    "print(\"üîß Setting up channel types and preparing data...\")\n",
    "\n",
    "# Create a copy for processing\n",
    "print(\"üìã Creating a working copy of the data for processing...\")\n",
    "print(\"   This preserves the original data for comparison and allows us to restart if needed.\")\n",
    "raw_processed = raw.copy()\n",
    "\n",
    "# Step 1: Identify and set EOG channel types\n",
    "print(\"\\nüëÅÔ∏è Identifying and setting EOG channel types...\")\n",
    "\n",
    "# Common EOG channel patterns to look for\n",
    "eog_patterns = [\n",
    "    'VEOG', 'HEOG',           # Vertical/Horizontal EOG (most common)\n",
    "    'EOG1', 'EOG2', 'EOG01', 'EOG02',  # Numbered EOG channels\n",
    "    'LEOG', 'REOG',           # Left/Right EOG\n",
    "    'LO1', 'LO2', 'IO1', 'IO2',  # Superior/Inferior Orbital\n",
    "    'SO1', 'SO2',             # Superior Orbital\n",
    "    'VREF', 'HREF',           # Vertical/Horizontal Reference\n",
    "    'EYE', 'BLINK'            # Other eye-related patterns\n",
    "]\n",
    "\n",
    "# Find EOG channels in the data\n",
    "eog_channels_found = []\n",
    "eog_channel_mapping = {}\n",
    "\n",
    "print(\"   üîç Scanning channel names for EOG patterns...\")\n",
    "for ch_name in raw_processed.ch_names:\n",
    "    ch_upper = ch_name.upper()\n",
    "    for pattern in eog_patterns:\n",
    "        if pattern in ch_upper:\n",
    "            eog_channels_found.append(ch_name)\n",
    "            eog_channel_mapping[ch_name] = 'eog'\n",
    "            print(f\"      ‚úÖ Found EOG channel: {ch_name}\")\n",
    "            break\n",
    "\n",
    "# Apply EOG channel type changes\n",
    "if eog_channels_found:\n",
    "    print(f\"\\n   üìù Setting {len(eog_channels_found)} channels to EOG type...\")\n",
    "    raw_processed.set_channel_types(eog_channel_mapping)\n",
    "    \n",
    "    # Verify the changes\n",
    "    for ch_name in eog_channels_found:\n",
    "        ch_idx = raw_processed.ch_names.index(ch_name)\n",
    "        ch_type = raw_processed.info['chs'][ch_idx]['kind']\n",
    "        if ch_type == mne.io.constants.FIFF.FIFFV_EOG_CH:\n",
    "            print(f\"      ‚úÖ {ch_name}: Successfully set to EOG\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è {ch_name}: Failed to set EOG type\")\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è No EOG channels found in data\")\n",
    "\n",
    "# Step 2: Get channel type summary (robust method)\n",
    "print(f\"\\nüìä Channel type summary:\")\n",
    "\n",
    "# Robust method to get channel types that works across MNE versions\n",
    "def get_channel_types_robust(raw):\n",
    "    \"\"\"Get channel types in a robust way across MNE versions\"\"\"\n",
    "    ch_types_dict = {}\n",
    "    \n",
    "    try:\n",
    "        # Method 1: Try get_channel_types() if available and returns dict\n",
    "        ch_types = raw.get_channel_types()\n",
    "        if isinstance(ch_types, dict):\n",
    "            return ch_types\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Method 2: Use info structure directly\n",
    "    try:\n",
    "        for i, ch_name in enumerate(raw.ch_names):\n",
    "            ch_kind = raw.info['chs'][i]['kind']\n",
    "            if ch_kind == mne.io.constants.FIFF.FIFFV_EEG_CH:\n",
    "                ch_types_dict[ch_name] = 'eeg'\n",
    "            elif ch_kind == mne.io.constants.FIFF.FIFFV_EOG_CH:\n",
    "                ch_types_dict[ch_name] = 'eog'\n",
    "            elif ch_kind == mne.io.constants.FIFF.FIFFV_ECG_CH:\n",
    "                ch_types_dict[ch_name] = 'ecg'\n",
    "            elif ch_kind == mne.io.constants.FIFF.FIFFV_EMG_CH:\n",
    "                ch_types_dict[ch_name] = 'emg'\n",
    "            elif ch_kind == mne.io.constants.FIFF.FIFFV_MISC_CH:\n",
    "                ch_types_dict[ch_name] = 'misc'\n",
    "            elif ch_kind == mne.io.constants.FIFF.FIFFV_STIM_CH:\n",
    "                ch_types_dict[ch_name] = 'stim'\n",
    "            else:\n",
    "                ch_types_dict[ch_name] = 'unknown'\n",
    "        return ch_types_dict\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Method 3: Fallback - assume all are EEG except known EOG\n",
    "    for ch_name in raw.ch_names:\n",
    "        if ch_name in eog_channels_found:\n",
    "            ch_types_dict[ch_name] = 'eog'\n",
    "        else:\n",
    "            ch_types_dict[ch_name] = 'eeg'\n",
    "    \n",
    "    return ch_types_dict\n",
    "\n",
    "# Get channel types using robust method\n",
    "ch_types_dict = get_channel_types_robust(raw_processed)\n",
    "\n",
    "# Create lists for each channel type\n",
    "eeg_channels = [ch for ch, ch_type in ch_types_dict.items() if ch_type == 'eeg']\n",
    "eog_channels = [ch for ch, ch_type in ch_types_dict.items() if ch_type == 'eog']\n",
    "other_channels = [ch for ch, ch_type in ch_types_dict.items() if ch_type not in ['eeg', 'eog']]\n",
    "\n",
    "# Update eog_channels list if we found more\n",
    "if eog_channels and eog_channels != eog_channels_found:\n",
    "    print(f\"   üîÑ Updated EOG channels list: {eog_channels}\")\n",
    "    eog_channels_found = eog_channels\n",
    "\n",
    "print(f\"   üìç EEG channels: {len(eeg_channels)}\")\n",
    "print(f\"   üëÅÔ∏è EOG channels: {len(eog_channels)}\")\n",
    "if other_channels:\n",
    "    # Get unique channel types for other channels\n",
    "    other_types = list(set([ch_types_dict[ch] for ch in other_channels]))\n",
    "    print(f\"   üîß Other channels: {len(other_channels)} (types: {other_types})\")\n",
    "\n",
    "# Show channel details\n",
    "if eog_channels:\n",
    "    print(f\"\\n   EOG channels found: {eog_channels}\")\n",
    "if len(eeg_channels) > 10:\n",
    "    print(f\"   EEG channels (first 10): {eeg_channels[:10]}...\")\n",
    "else:\n",
    "    print(f\"   EEG channels: {eeg_channels}\")\n",
    "\n",
    "# Step 3: Create EEG-only version for montage and main processing\n",
    "print(f\"\\nüß† Creating EEG-only dataset for main processing...\")\n",
    "raw_eeg_only = raw_processed.copy().pick('eeg')\n",
    "print(f\"   ‚úÖ EEG-only dataset created with {len(raw_eeg_only.ch_names)} channels\")\n",
    "\n",
    "# Step 4: Set up channel montage on EEG channels\n",
    "print(\"\\nüó∫Ô∏è Setting up channel montage for EEG channels...\")\n",
    "\n",
    "# Try BrainProducts montage first, then fallbacks\n",
    "montage_candidates = [\n",
    "    'brainproducts-RNP-BA-128',\n",
    "    'standard_1020',\n",
    "    'standard_1005', \n",
    "    'easycap-M1',\n",
    "    'biosemi64'\n",
    "]\n",
    "\n",
    "montage_set = False\n",
    "montage_name = None\n",
    "\n",
    "for candidate_montage in montage_candidates:\n",
    "    try:\n",
    "        print(f\"   üéØ Trying {candidate_montage} montage...\")\n",
    "        montage = mne.channels.make_standard_montage(candidate_montage)\n",
    "        \n",
    "        # Apply montage to EEG-only data\n",
    "        raw_eeg_only.set_montage(montage, match_case=False, on_missing='ignore', verbose=False)\n",
    "        \n",
    "        # Check if any channels were matched\n",
    "        n_matched = sum(1 for ch in raw_eeg_only.info['chs'] if ch['loc'][0] != 0)\n",
    "        match_percentage = (n_matched / len(raw_eeg_only.ch_names)) * 100\n",
    "        \n",
    "        print(f\"      üìç Matched: {n_matched}/{len(raw_eeg_only.ch_names)} channels ({match_percentage:.1f}%)\")\n",
    "        \n",
    "        if n_matched > len(raw_eeg_only.ch_names) * 0.5:  # At least 50% matched\n",
    "            print(f\"   ‚úÖ Successfully applied {candidate_montage} montage\")\n",
    "            montage_name = candidate_montage\n",
    "            montage_set = True\n",
    "            \n",
    "            # Show matched/unmatched channels\n",
    "            matched_channels = [ch_name for i, ch_name in enumerate(raw_eeg_only.ch_names) \n",
    "                               if raw_eeg_only.info['chs'][i]['loc'][0] != 0]\n",
    "            unmatched_channels = [ch_name for i, ch_name in enumerate(raw_eeg_only.ch_names) \n",
    "                                 if raw_eeg_only.info['chs'][i]['loc'][0] == 0]\n",
    "            \n",
    "            if len(matched_channels) <= 10:\n",
    "                print(f\"      ‚úÖ Matched channels: {matched_channels}\")\n",
    "            else:\n",
    "                print(f\"      ‚úÖ Matched channels (first 10): {matched_channels[:10]}...\")\n",
    "                \n",
    "            if unmatched_channels:\n",
    "                if len(unmatched_channels) <= 5:\n",
    "                    print(f\"      ‚ö†Ô∏è Unmatched channels: {unmatched_channels}\")\n",
    "                else:\n",
    "                    print(f\"      ‚ö†Ô∏è Unmatched channels (first 5): {unmatched_channels[:5]}...\")\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            print(f\"      ‚ùå Insufficient matches ({match_percentage:.1f}%), trying next montage...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ùå Failed to apply {candidate_montage}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not montage_set:\n",
    "    print(\"‚ö†Ô∏è No standard montage provided sufficient channel matches.\")\n",
    "    print(\"   Proceeding without spatial information (some analyses may be limited).\")\n",
    "\n",
    "# Step 5: Apply montage back to full dataset (including EOG)\n",
    "if montage_set:\n",
    "    print(f\"\\nüîÑ Applying {montage_name} montage to full dataset...\")\n",
    "    try:\n",
    "        montage = mne.channels.make_standard_montage(montage_name)\n",
    "        raw_processed.set_montage(montage, match_case=False, on_missing='ignore', verbose=False)\n",
    "        print(\"   ‚úÖ Montage applied to full dataset (EEG + EOG)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not apply montage to full dataset: {e}\")\n",
    "\n",
    "# Step 6: Set processing dataset (use EEG-only for main processing)\n",
    "print(f\"\\nüéØ Setting up processing dataset...\")\n",
    "print(\"   üìã For preprocessing pipeline, we'll use EEG-only data\")\n",
    "print(\"   üìã EOG channels will be available for artifact removal when needed\")\n",
    "\n",
    "# Use EEG-only data as the main processing dataset\n",
    "raw_for_processing = raw_eeg_only.copy()\n",
    "\n",
    "print(f\"\\nüìä Final setup summary:\")\n",
    "print(f\"   Original dataset: {len(raw.ch_names)} channels\")\n",
    "print(f\"   EEG channels: {len(eeg_channels)} channels\")\n",
    "print(f\"   EOG channels: {len(eog_channels)} channels\")\n",
    "print(f\"   Processing dataset: {len(raw_for_processing.ch_names)} EEG channels\")\n",
    "print(f\"   Montage applied: {montage_name if montage_set else 'None'}\")\n",
    "\n",
    "# Channel locations (if montage was set)\n",
    "if montage_set:\n",
    "    print(\"   üó∫Ô∏è Plotting channel locations...\")\n",
    "    try:\n",
    "        raw_processed.plot_sensors(kind='topomap', show_names=True, show=False)\n",
    "        plt.title('All Channel Locations')\n",
    "        plt.gcf().set_constrained_layout(True)\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not plot channel locations: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Channel setup and montage configuration completed!\")\n",
    "print(f\"   üìä Ready to proceed with preprocessing pipeline using {len(raw_for_processing.ch_names)} EEG channels\")\n",
    "print(f\"   üëÅÔ∏è EOG channels ({eog_channels}) remain available in full dataset for artifact removal\")\n",
    "\n",
    "# Update variables for the rest of the preprocessing pipeline\n",
    "raw_processed = raw_for_processing  # This will be used for the rest of preprocessing\n",
    "\n",
    "# Store references for later use\n",
    "eog_channels = eog_channels_found  # Make sure eog_channels variable is available globally"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-pipeline",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Pipeline {#preprocessing-pipeline}\n",
    "\n",
    "**Overview**: This section applies the complete CleanEEG preprocessing workflow following the DISCOVER-EEG framework. Each step targets specific types of artifacts while preserving neural signals.\n",
    "\n",
    "**Pipeline Logic**: Steps are ordered to handle the largest artifacts first (line noise, drifts) before more sophisticated analyses (ICA, ASR) that work better on cleaner data. Quality metrics after each step confirm improvements.\n",
    "\n",
    "**Key Principle**: Every preprocessing step should improve signal quality. We'll monitor this with quantitative metrics throughout.\n",
    "\n",
    "Now we'll apply the complete CleanEEG preprocessing pipeline, monitoring quality at each step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "line-noise",
   "metadata": {},
   "source": [
    "### 5.1 Line Noise Removal (Denoising Source Separation) {#line-noise}\n",
    "\n",
    "**Purpose**: Remove electrical interference from power lines (50/60 Hz) that contaminates EEG signals.\n",
    "\n",
    "**Why needed**: Power line noise creates strong, narrow-band artifacts that can overwhelm neural signals and distort frequency analysis. This interference comes from electrical equipment and building wiring.\n",
    "\n",
    "**Method**: Denoising Source Separation (DSS) is superior to simple notch filtering because it removes line noise while preserving neural activity at the same frequencies."
   ]
  },
  {
   "cell_type": "code",
   "id": "line-noise-removal",
   "metadata": {},
   "source": [
    "from meegkit import dss\n",
    "\n",
    "print(\"‚ö° Removing line noise using Denoising Source Separation (DSS)...\")\n",
    "\n",
    "# Line frequency depends on geographical location:\n",
    "# - 50 Hz: Europe, Asia, Africa, Australia (most of the world)\n",
    "# - 60 Hz: North America, parts of South America, some Pacific islands\n",
    "# Since this dataset was collected in Germany (LEMON dataset), we use 50 Hz\n",
    "line_freq = 50\n",
    "print(f\"   üåç Using {line_freq} Hz line frequency (European power grid standard)\")\n",
    "\n",
    "# Get the EEG data\n",
    "data = raw_processed.get_data()\n",
    "sfreq = raw_processed.info['sfreq']\n",
    "\n",
    "# Optional: Verify line noise presence at target frequency\n",
    "print(f\"   üîç Checking line noise power at {line_freq} Hz...\")\n",
    "freqs, psd = signal.welch(data, sfreq, nperseg=int(2*sfreq))\n",
    "freq_idx = np.argmin(np.abs(freqs - line_freq))\n",
    "\n",
    "power_line_freq = np.mean(psd[:, freq_idx])\n",
    "print(f\"      - Power at {line_freq} Hz: {power_line_freq:.2e}\")\n",
    "\n",
    "# Compare to neighboring frequencies for context\n",
    "neighbor_freqs = [line_freq - 2, line_freq + 2]  # ¬±2 Hz from line frequency\n",
    "neighbor_powers = []\n",
    "for neighbor_freq in neighbor_freqs:\n",
    "    neighbor_idx = np.argmin(np.abs(freqs - neighbor_freq))\n",
    "    neighbor_power = np.mean(psd[:, neighbor_idx])\n",
    "    neighbor_powers.append(neighbor_power)\n",
    "    \n",
    "avg_neighbor_power = np.mean(neighbor_powers)\n",
    "line_noise_ratio = power_line_freq / avg_neighbor_power\n",
    "print(f\"      - Average power at {neighbor_freqs[0]}-{neighbor_freqs[1]} Hz: {avg_neighbor_power:.2e}\")\n",
    "print(f\"      - Line noise prominence: {line_noise_ratio:.1f}x above neighbors\")\n",
    "\n",
    "# Apply DSS line noise removal\n",
    "try:\n",
    "    print(f\"   üîß Applying DSS to remove {line_freq} Hz line noise...\")\n",
    "    processed_data, artifacts = dss.dss_line(\n",
    "        data.T,                          # Data must be (time x channels)\n",
    "        fline=line_freq,                 # Line frequency to target\n",
    "        sfreq=sfreq,                     # Sampling frequency\n",
    "        show=False                       # Don't show plots\n",
    "    )\n",
    "    \n",
    "    # Update the data in our raw object\n",
    "    raw_processed._data = processed_data.T  # Convert back to (channels x time)\n",
    "    \n",
    "    print(f\"   ‚úÖ DSS line noise removal completed\")\n",
    "    print(f\"      - Targeted frequency: {line_freq} Hz\")\n",
    "    print(f\"      - Method: Denoising Source Separation\")\n",
    "    \n",
    "    # Store version\n",
    "    raw_versions['After Line Noise Removal'] = raw_processed.copy()\n",
    "    \n",
    "    # Quality assessment\n",
    "    snr_after_line = compute_snr(raw_processed, method='spectral')\n",
    "    processing_log['After Line Noise'] = snr_after_line\n",
    "    print_snr_summary(snr_after_line, \"After Line Noise Removal\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è DSS line noise removal failed: {e}\")\n",
    "    print(\"   üîÑ Falling back to notch filter...\")\n",
    "    \n",
    "    # Fallback to notch filter\n",
    "    raw_processed.notch_filter(freqs=[line_freq], verbose=False)\n",
    "    \n",
    "    print(f\"   ‚úÖ Notch filter applied at {line_freq} Hz\")\n",
    "    \n",
    "    raw_versions['After Line Noise Removal'] = raw_processed.copy()\n",
    "    snr_after_line = compute_snr(raw_processed, method='spectral')\n",
    "    processing_log['After Line Noise'] = snr_after_line\n",
    "    print_snr_summary(snr_after_line, \"After Notch Filter\")\n",
    "\n",
    "# Verify line noise reduction\n",
    "print(\"   üìä Verifying line noise reduction...\")\n",
    "data_after = raw_processed.get_data()\n",
    "freqs_after, psd_after = signal.welch(data_after, sfreq, nperseg=int(2*sfreq))\n",
    "freq_idx_after = np.argmin(np.abs(freqs_after - line_freq))\n",
    "power_line_freq_after = np.mean(psd_after[:, freq_idx_after])\n",
    "\n",
    "reduction_db = 10 * np.log10(power_line_freq / (power_line_freq_after + 1e-12))\n",
    "print(f\"      - Line noise reduction: {reduction_db:.1f} dB at {line_freq} Hz\")\n",
    "\n",
    "# Plot comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['Original'], raw_versions['After Line Noise Removal']], \n",
    "    ['Original', 'After Line Noise Removal'],\n",
    "    \"PSD: Before vs After Line Noise Removal\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "highpass-filter",
   "metadata": {},
   "source": [
    "### 5.2 Bandpass Filter {#bandpass-filter}\n",
    "\n",
    "**Purpose**: Remove slow drifts, baseline shifts, and high-frequency noise from EEG recordings.\n",
    "\n",
    "**Why needed**: EEG amplifiers can introduce very low-frequency drifts (<1 Hz) due to electrode movement, skin conductance changes, and amplifier instabilities. Additionally, high-frequency noise (>100 Hz) from electrical interference, muscle artifacts, and amplifier noise can contaminate the signal. These artifacts can distort analyses and make data appear non-stationary.\n",
    "\n",
    "**Method**: A 1-100 Hz bandpass filter combines:\n",
    "- **Highpass component (1 Hz)**: Removes slow drifts while preserving all neural frequencies of interest (delta waves start at ~1-4 Hz)\n",
    "- **Lowpass component (100 Hz)**: Removes high-frequency noise while retaining all relevant neural oscillations including gamma activity (30-100 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "id": "highpass-filtering",
   "metadata": {},
   "source": [
    "print(\"üîΩ Applying bandpass filter...\")\n",
    "\n",
    "# Apply bandpass filter at 1 Hz to remove slow drifts\n",
    "hp_freq = 1.0\n",
    "lp_freq = 100.0\n",
    "raw_processed.filter(\n",
    "    l_freq=hp_freq,   # High-pass cutoff\n",
    "    h_freq=lp_freq,   # Low-pass cutoff\n",
    "    method='fir',     # Finite Impulse Response filter\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Highpass filter applied at {hp_freq} Hz and Lowpass filter applied at {lp_freq} Hz\")\n",
    "\n",
    "# Store version\n",
    "raw_versions['After Bandpass Filter'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_hp = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After Bandpass'] = snr_after_hp\n",
    "print_snr_summary(snr_after_hp, \"After Bandpass Filter\")\n",
    "\n",
    "# Plot comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Line Noise Removal'], raw_versions['After Bandpass Filter']], \n",
    "    ['After Line Noise Removal', 'After Bandpass Filter'],\n",
    "    \"PSD: Before vs After Bandpass Filter\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "downsample",
   "metadata": {},
   "source": [
    "### 5.3 Downsample Data {#downsample}\n",
    "\n",
    "**Purpose**: Reduce data size and computational load while preserving all relevant neural information.\n",
    "\n",
    "**Why needed**: Many EEG systems record at very high sampling rates (>1000 Hz) to avoid aliasing, but most EEG analysis only requires frequencies up to 100-200 Hz. High sampling rates create unnecessarily large files and slow processing.\n",
    "\n",
    "**Method**: Downsample to 500 Hz (adequate for frequencies up to 250 Hz) after applying anti-aliasing filters to prevent frequency distortion."
   ]
  },
  {
   "cell_type": "code",
   "id": "downsampling",
   "metadata": {},
   "source": [
    "print(\"üìâ Downsampling data...\")\n",
    "\n",
    "# Downsample to 500 Hz (adequate for most EEG analyses)\n",
    "target_sfreq = 500\n",
    "original_sfreq = raw_processed.info['sfreq']\n",
    "\n",
    "if original_sfreq > target_sfreq:\n",
    "    raw_processed.resample(target_sfreq, verbose=False)\n",
    "    print(f\"   ‚úÖ Downsampled from {original_sfreq} Hz to {target_sfreq} Hz\")\n",
    "    print(f\"   üìä Data reduction: {(1 - target_sfreq/original_sfreq)*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"   ‚ÑπÔ∏è No downsampling needed (current: {original_sfreq} Hz)\")\n",
    "\n",
    "# Store version\n",
    "raw_versions['After Downsampling'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_downsample = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After Downsample'] = snr_after_downsample\n",
    "print_snr_summary(snr_after_downsample, \"After Downsampling\")\n",
    "\n",
    "# Plot comparison (focus on frequencies up to new Nyquist)\n",
    "nyquist_freq = min(target_sfreq/2, 100)\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Bandpass Filter'], raw_versions['After Downsampling']], \n",
    "    ['Before Downsampling', 'After Downsampling'],\n",
    "    \"PSD: Before vs After Downsampling\",\n",
    "    fmax=nyquist_freq\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bad-channels",
   "metadata": {},
   "source": [
    "### 5.4 Bad Channel Rejection (PREP Pipeline) {#bad-channels}\n",
    "\n",
    "**Purpose**: Automatically identify and mark electrodes that are not recording valid neural signals.\n",
    "\n",
    "**Why needed**: EEG electrodes can malfunction due to poor skin contact, broken wires, high impedance, or movement artifacts. Bad channels introduce noise and can distort spatial analyses, source localization, and connectivity measures.\n",
    "\n",
    "**Method**: The PREP pipeline uses multiple statistical criteria: flat channels, channels with extreme amplitudes, poor correlation with neighbors, and channels that deviate from robust signal statistics."
   ]
  },
  {
   "cell_type": "code",
   "id": "bad-channel-detection",
   "metadata": {},
   "source": [
    "print(\"üîç Detecting bad channels using PREP pipeline...\")\n",
    "\n",
    "try:\n",
    "    from pyprep.find_noisy_channels import NoisyChannels\n",
    "    \n",
    "    # Create a NoisyChannels object\n",
    "    nd = NoisyChannels(raw_processed, random_state=42)\n",
    "    \n",
    "    # Find all types of bad channels\n",
    "    nd.find_all_bads(ransac=True, channel_wise=True, max_chunk_size=None)\n",
    "    \n",
    "    # Get the detected bad channels\n",
    "    bad_channels = nd.get_bads()\n",
    "    \n",
    "    if bad_channels:\n",
    "        print(f\"   üö´ Detected bad channels: {bad_channels}\")\n",
    "        \n",
    "        # Mark channels as bad\n",
    "        raw_processed.info['bads'] = bad_channels\n",
    "        \n",
    "        # Show channel types found\n",
    "        for bad_type in ['bad_by_nan', 'bad_by_flat', 'bad_by_deviation', \n",
    "                        'bad_by_hf_noise', 'bad_by_correlation', 'bad_by_ransac']:\n",
    "            bad_chans = getattr(nd, bad_type, [])\n",
    "            if bad_chans:\n",
    "                print(f\"      - {bad_type.replace('bad_by_', '').replace('_', ' ').title()}: {bad_chans}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No bad channels detected\")\n",
    "    \n",
    "    prep_success = True\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è PREP pipeline failed: {e}\")\n",
    "    print(\"   Using simple statistical bad channel detection...\")\n",
    "    \n",
    "    # Fallback: simple statistical method\n",
    "    data = raw_processed.get_data()\n",
    "    \n",
    "    # Find channels with extreme variance\n",
    "    channel_vars = np.var(data, axis=1)\n",
    "    var_threshold_high = np.percentile(channel_vars, 95)\n",
    "    var_threshold_low = np.percentile(channel_vars, 5)\n",
    "    \n",
    "    bad_channels = []\n",
    "    for i, ch_name in enumerate(raw_processed.ch_names):\n",
    "        if channel_vars[i] > var_threshold_high or channel_vars[i] < var_threshold_low:\n",
    "            bad_channels.append(ch_name)\n",
    "    \n",
    "    if bad_channels:\n",
    "        print(f\"   üö´ Detected bad channels (statistical): {bad_channels}\")\n",
    "        raw_processed.info['bads'] = bad_channels\n",
    "    else:\n",
    "        print(\"   ‚úÖ No bad channels detected (statistical method)\")\n",
    "    \n",
    "    prep_success = False\n",
    "\n",
    "# Store version\n",
    "raw_versions['After Bad Channel Detection'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment (excluding bad channels)\n",
    "snr_after_bad_chans = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After Bad Channels'] = snr_after_bad_chans\n",
    "print_snr_summary(snr_after_bad_chans, \"After Bad Channel Detection\")\n",
    "\n",
    "print(f\"\\nüìã Bad Channel Summary:\")\n",
    "print(f\"   Total channels: {len(raw_processed.ch_names)}\")\n",
    "print(f\"   Bad channels: {len(raw_processed.info['bads'])}\")\n",
    "print(f\"   Good channels: {len(raw_processed.ch_names) - len(raw_processed.info['bads'])}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eog-removal",
   "metadata": {},
   "source": [
    "### 5.5 EOG Artifact Removal {#eog-removal}\n",
    "\n",
    "**Purpose**: Remove eye movement and blink artifacts that contaminate frontal EEG electrodes.\n",
    "\n",
    "**Why needed**: Eye movements and blinks generate large electrical potentials (much larger than neural signals) that spread to frontal and temporal EEG channels. These artifacts can completely obscure brain activity and create false patterns in analysis.\n",
    "\n",
    "**Method**: EOG regression uses dedicated eye movement channels to model and subtract eye-related artifacts from EEG channels, preserving underlying neural activity."
   ]
  },
  {
   "cell_type": "code",
   "id": "eog-artifact-removal",
   "metadata": {},
   "source": [
    "print(\"üëÅÔ∏è Simple EOG artifact removal...\")\n",
    "\n",
    "# Check if we have EOG channels\n",
    "if 'eog_channels' in locals() and eog_channels and len(eog_channels) > 0:\n",
    "    print(f\"   üìç Found {len(eog_channels)} EOG channels: {eog_channels}\")\n",
    "    \n",
    "    try:\n",
    "        from mne.preprocessing import EOGRegression\n",
    "        \n",
    "        print(\"   üîß Preparing data for EOG regression...\")\n",
    "        \n",
    "        # Method 1: Use the original raw data that contains both EEG and EOG\n",
    "        raw_full = raw.copy()  # Original data with all channels\n",
    "        \n",
    "        # Ensure we have the right channel types\n",
    "        print(\"   üìù Setting up channel types...\")\n",
    "        \n",
    "        # Get all channel names\n",
    "        all_ch_names = raw_full.ch_names.copy()\n",
    "        \n",
    "        # Separate EEG and EOG channels\n",
    "        eeg_ch_names = [ch for ch in all_ch_names if ch not in eog_channels]\n",
    "        \n",
    "        print(f\"      EEG channels: {len(eeg_ch_names)}\")\n",
    "        print(f\"      EOG channels: {len(eog_channels)}\")\n",
    "        \n",
    "        # Set channel types explicitly\n",
    "        channel_types = {}\n",
    "        for ch in eeg_ch_names:\n",
    "            channel_types[ch] = 'eeg'\n",
    "        for ch in eog_channels:\n",
    "            channel_types[ch] = 'eog'\n",
    "            \n",
    "        raw_full.set_channel_types(channel_types)\n",
    "        print(f\"   ‚úÖ Channel types set: {len(eeg_ch_names)} EEG, {len(eog_channels)} EOG\")\n",
    "        \n",
    "        # Set average reference for EEG channels (required for EOG regression)\n",
    "        print(\"   üìä Setting average reference for EEG channels...\")\n",
    "        raw_full.set_eeg_reference('average', projection=True, verbose=False)\n",
    "        print(\"   ‚úÖ Average reference set\")\n",
    "        \n",
    "        # Verify we have both EEG and EOG channels\n",
    "        eeg_picks = mne.pick_types(raw_full.info, eeg=True)\n",
    "        eog_picks = mne.pick_types(raw_full.info, eog=True)\n",
    "        \n",
    "        print(f\"   üîç Verification - EEG channels found: {len(eeg_picks)}, EOG channels found: {len(eog_picks)}\")\n",
    "        \n",
    "        if len(eeg_picks) == 0:\n",
    "            raise ValueError(\"No EEG channels found for EOG regression\")\n",
    "        if len(eog_picks) == 0:\n",
    "            raise ValueError(\"No EOG channels found for EOG regression\")\n",
    "        \n",
    "        # Apply EOG regression\n",
    "        print(\"   üîÑ Applying EOG regression...\")\n",
    "        eog_regression = EOGRegression(\n",
    "            picks='eeg',           # Apply to EEG channels\n",
    "            picks_artifact='eog'   # Use EOG channels as reference\n",
    "        )\n",
    "        \n",
    "        # Fit the regression model\n",
    "        print(\"   üìà Fitting EOG regression model...\")\n",
    "        eog_regression.fit(raw_full)\n",
    "        print(\"   ‚úÖ EOG regression model fitted\")\n",
    "        \n",
    "        # Apply regression to get cleaned data\n",
    "        raw_cleaned = eog_regression.apply(raw_full, copy=True)\n",
    "        print(\"   ‚úÖ EOG regression applied\")\n",
    "        \n",
    "        # Extract only EEG channels for continued processing\n",
    "        eeg_channel_names = [ch for ch in raw_cleaned.ch_names if ch not in eog_channels]\n",
    "        raw_processed_new = raw_cleaned.copy().pick(eeg_channel_names)\n",
    "        \n",
    "        print(f\"   üìä Extracted {len(raw_processed_new.ch_names)} EEG channels after EOG removal\")\n",
    "        \n",
    "        # Calculate improvement\n",
    "        data_before = raw_processed.get_data()\n",
    "        data_after   = raw_processed_new.get_data()\n",
    "        \n",
    "        min_channels = min(data_before.shape[0], data_after.shape[0])\n",
    "        variance_before = np.var(data_before[:min_channels])\n",
    "        variance_after  = np.var(data_after[:min_channels])\n",
    "        \n",
    "        if variance_before > 0:\n",
    "            variance_reduction = ((variance_before - variance_after) / variance_before) * 100\n",
    "            print(f\"   üìà Variance reduction: {variance_reduction:.1f}%\")\n",
    "        \n",
    "        # Update processing dataset\n",
    "        raw_processed = raw_processed_new\n",
    "        \n",
    "        # Store for comparison\n",
    "        raw_versions['After EOG Removal'] = raw_processed.copy()\n",
    "        \n",
    "        # --- üîß QUALITY LOG UPDATE ---\n",
    "        snr_after_eog = compute_snr(raw_processed)        # calculate SNR metrics\n",
    "        processing_log['After EOG Removal'] = snr_after_eog\n",
    "        print_snr_summary(snr_after_eog, 'After EOG Removal')\n",
    "        # -------------------------------------------------------------------------\n",
    "        \n",
    "        # Show comparison if we have previous version\n",
    "        if len(raw_versions) >= 2:\n",
    "            version_keys = list(raw_versions.keys())\n",
    "            plot_psd_comparison(\n",
    "                [raw_versions[version_keys[-2]],\n",
    "                 raw_versions[version_keys[-1]]],\n",
    "                labels=[version_keys[-2], version_keys[-1]],\n",
    "                title=\"PSD Before vs After EOG Removal\"\n",
    "            )\n",
    "        \n",
    "        print(\"   ‚úÖ EOG regression completed successfully\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"   ‚ö†Ô∏è EOGRegression not available, skipping EOG removal\")\n",
    "        raw_versions['After EOG Removal'] = raw_processed.copy()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è EOG regression failed: {e}\")\n",
    "        print(\"   üîÑ Trying alternative EOG removal approach...\")\n",
    "        \n",
    "        try:\n",
    "            # Alternative approach: Simple linear regression\n",
    "            print(\"   üìä Using simple linear regression approach...\")\n",
    "            \n",
    "            # Get EEG and EOG data\n",
    "            raw_eeg = raw.copy().pick([ch for ch in raw.ch_names if ch not in eog_channels])\n",
    "            raw_eog = raw.copy().pick(eog_channels)\n",
    "            \n",
    "            # Set average reference for EEG\n",
    "            raw_eeg.set_eeg_reference('average', projection=False, verbose=False)\n",
    "            \n",
    "            # Get the data arrays\n",
    "            eeg_data = raw_eeg.get_data()  # Shape: (n_eeg_channels, n_times)\n",
    "            eog_data = raw_eog.get_data()  # Shape: (n_eog_channels, n_times)\n",
    "            \n",
    "            print(f\"      EEG data shape: {eeg_data.shape}\")\n",
    "            print(f\"      EOG data shape: {eog_data.shape}\")\n",
    "            \n",
    "            # Simple regression: for each EEG channel, regress out EOG\n",
    "            eeg_cleaned = eeg_data.copy()\n",
    "            \n",
    "            for i, eeg_ch in enumerate(raw_eeg.ch_names):\n",
    "                for j, eog_ch in enumerate(eog_channels):\n",
    "                    eog_signal = eog_data[j, :]\n",
    "                    eeg_signal = eeg_cleaned[i, :]\n",
    "                    \n",
    "                    covariance   = np.cov(eeg_signal, eog_signal)[0, 1]\n",
    "                    eog_variance = np.var(eog_signal)\n",
    "                    \n",
    "                    if eog_variance > 0:\n",
    "                        beta = covariance / eog_variance\n",
    "                        eeg_cleaned[i, :] = eeg_signal - beta * eog_signal\n",
    "            \n",
    "            # Create new raw object with cleaned EEG data\n",
    "            raw_processed_new = mne.io.RawArray(eeg_cleaned, raw_eeg.info.copy(), verbose=False)\n",
    "            \n",
    "            print(\"   ‚úÖ Alternative EOG removal applied\")\n",
    "            \n",
    "            # Calculate improvement\n",
    "            variance_before = np.var(eeg_data)\n",
    "            variance_after  = np.var(eeg_cleaned)\n",
    "            \n",
    "            if variance_before > 0:\n",
    "                variance_reduction = ((variance_before - variance_after) / variance_before) * 100\n",
    "                print(f\"   üìà Variance reduction: {variance_reduction:.1f}%\")\n",
    "            \n",
    "            # Update processing dataset\n",
    "            raw_processed = raw_processed_new\n",
    "            \n",
    "            # Store for comparison\n",
    "            raw_versions['After EOG Removal'] = raw_processed.copy()\n",
    "            \n",
    "            # --- üîß QUALITY LOG UPDATE -----------------------\n",
    "            snr_after_eog = compute_snr(raw_processed)\n",
    "            processing_log['After EOG Removal'] = snr_after_eog\n",
    "            print_snr_summary(snr_after_eog, 'After EOG Removal')\n",
    "            # ---------------------------------------------------------------------\n",
    "            \n",
    "            print(\"   ‚úÖ Alternative EOG removal completed successfully\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"   ‚ö†Ô∏è Alternative EOG removal also failed: {e2}\")\n",
    "            print(\"   üìã Continuing without EOG correction...\")\n",
    "            \n",
    "            raw_versions['After EOG Removal'] = raw_processed.copy()\n",
    "            \n",
    "            if processing_log:\n",
    "                last_key = list(processing_log.keys())[-1]\n",
    "                processing_log['After EOG Removal'] = processing_log[last_key].copy()\n",
    "\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è No EOG channels found - skipping EOG artifact removal\")\n",
    "    \n",
    "    raw_versions['After EOG Removal'] = raw_processed.copy()\n",
    "    \n",
    "    if processing_log:\n",
    "        last_key = list(processing_log.keys())[-1]\n",
    "        processing_log['After EOG Removal'] = processing_log[last_key].copy()\n",
    "        print_snr_summary(processing_log['After EOG Removal'], \n",
    "                                 \"No EOG Removal (Skipped)\")\n",
    "\n",
    "print(f\"\\n‚úÖ EOG processing step completed\")\n",
    "print(f\"   üìä Processing dataset: {len(raw_processed.ch_names)} EEG channels\")\n",
    "print(f\"   üëÅÔ∏è EOG regression: {'Applied' if eog_channels and len(eog_channels) > 0 else 'Skipped'}\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready to continue with next preprocessing step!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ica",
   "metadata": {},
   "source": [
    "### 5.6 Independent Component Analysis (ICA) {#ica}\n",
    "\n",
    "**Purpose**: Separate mixed EEG signals into independent components and remove non-neural artifacts.\n",
    "\n",
    "**Why needed**: EEG signals are mixtures of neural activity, muscle artifacts, heart beats, eye movements, and other noise sources. These artifacts can't always be removed by simple filtering and often overlap with neural frequencies.\n",
    "\n",
    "**Method**: ICA decomposes the signal into statistically independent components. ICLabel automatically classifies components as brain activity, muscle, eye blinks, heart beats, or noise, allowing selective removal of artifacts while preserving neural signals."
   ]
  },
  {
   "cell_type": "code",
   "id": "ica-analysis",
   "metadata": {},
   "source": [
    "print(\"üß† Performing Independent Component Analysis (ICA)...\")\n",
    "\n",
    "try:\n",
    "    from mne.preprocessing import ICA\n",
    "    from mne_icalabel import label_components\n",
    "    \n",
    "    # Create a copy for ICA (excluding bad channels)\n",
    "    raw_for_ica = raw_processed.copy().pick('eeg', exclude='bads')\n",
    "    \n",
    "    # Re-reference to average for better ICA decomposition\n",
    "    raw_for_ica.set_eeg_reference('average', projection=False, verbose=False)\n",
    "    \n",
    "    # Create ICA object\n",
    "    ica = ICA(\n",
    "        n_components=None,\n",
    "        method='fastica',\n",
    "        random_state=42,\n",
    "        max_iter='auto'\n",
    "        )\n",
    "    \n",
    "    print(f\"   üîß Fitting ICA ...\")\n",
    "    ica.fit(raw_for_ica, verbose=False)\n",
    "    \n",
    "    # Use ICLabel for automatic component classification\n",
    "    print(\"   üè∑Ô∏è Classifying components with ICLabel...\")\n",
    "    ic_labels = label_components(raw_for_ica, ica, method='iclabel')\n",
    "    \n",
    "    # Get component labels and probabilities\n",
    "    labels = ic_labels['labels']\n",
    "    probabilities = ic_labels['y_pred_proba']\n",
    "    \n",
    "    # Define components to exclude (artifacts)\n",
    "    artifact_types = ['muscle artifact', 'eye blink', 'heart beat', 'line noise', 'channel noise']\n",
    "    \n",
    "    exclude_idx = []\n",
    "    component_summary = {}\n",
    "    \n",
    "    for i, (label, probs) in enumerate(zip(labels, probabilities)):\n",
    "        component_summary[f'IC{i:02d}'] = {\n",
    "            'label': label,\n",
    "            'confidence': np.max(probs)\n",
    "        }\n",
    "        \n",
    "        # Exclude components that are artifacts with high confidence\n",
    "        if label in artifact_types and np.max(probs) > 0.7:\n",
    "            exclude_idx.append(i)\n",
    "    \n",
    "    print(f\"\\n   üìä Component Classification Summary:\")\n",
    "    for comp, info in component_summary.items():\n",
    "        status = \"üö´ EXCLUDE\" if int(comp[2:]) in exclude_idx else \"‚úÖ KEEP\"\n",
    "        print(f\"      {comp}: {info['label']} (conf: {info['confidence']:.2f}) {status}\")\n",
    "    \n",
    "    # Set components to exclude\n",
    "    ica.exclude = exclude_idx\n",
    "    \n",
    "    print(f\"\\n   üóëÔ∏è Excluding {len(exclude_idx)} artifactual components\")\n",
    "    \n",
    "    # Apply ICA to the original data (with bad channels)\n",
    "    raw_processed = ica.apply(raw_processed, verbose=False)\n",
    "    \n",
    "    print(\"   ‚úÖ ICA applied successfully\")\n",
    "    \n",
    "    # Plot ICA components (first 12)\n",
    "    if len(ica.exclude) > 0:\n",
    "        fig = ica.plot_components(picks=range(min(12, ica.n_components_)), \n",
    "                                 title='ICA Components (Red = Excluded)', show=False)\n",
    "        plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è ICA failed: {e}\")\n",
    "    print(\"   Proceeding without ICA component removal\")\n",
    "\n",
    "# Store version\n",
    "raw_versions['After ICA'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_ica = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After ICA'] = snr_after_ica\n",
    "print_snr_summary(snr_after_ica, \"After ICA\")\n",
    "\n",
    "# Plot comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After EOG Removal'], raw_versions['After ICA']], \n",
    "    ['Before ICA', 'After ICA'],\n",
    "    \"PSD: Before vs After ICA\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "interpolation",
   "metadata": {},
   "source": [
    "### 5.7 Bad Channel Interpolation {#interpolation}\n",
    "\n",
    "**Purpose**: Restore the full electrode array by estimating signals at previously identified bad channel locations.\n",
    "\n",
    "**Why needed**: Many analyses (especially connectivity and source localization) require a complete, uniform electrode montage. Missing channels create gaps in spatial coverage and can bias results toward areas with higher electrode density.\n",
    "\n",
    "**Method**: Spherical spline interpolation uses signals from neighboring good electrodes to estimate what the signal would have been at bad electrode locations, based on the spatial smoothness of scalp potentials."
   ]
  },
  {
   "cell_type": "code",
   "id": "channel-interpolation",
   "metadata": {},
   "source": [
    "print(\"üîß Interpolating bad channels...\")\n",
    "\n",
    "n_bad_channels = len(raw_processed.info['bads'])\n",
    "\n",
    "if n_bad_channels > 0:\n",
    "    print(f\"   üìç Interpolating {n_bad_channels} bad channels: {raw_processed.info['bads']}\")\n",
    "    \n",
    "    try:\n",
    "        # Interpolate bad channels\n",
    "        raw_processed.interpolate_bads(reset_bads=True, verbose=False)\n",
    "        print(\"   ‚úÖ Bad channels interpolated successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Channel interpolation failed: {e}\")\n",
    "        print(\"   This might be due to missing channel locations\")\n",
    "        \n",
    "        # Reset bads list if interpolation failed\n",
    "        raw_processed.info['bads'] = []\nelse:\n",
    "    print(\"   ‚ÑπÔ∏è No bad channels to interpolate\")\n",
    "\n",
    "# Store version\n",
    "raw_versions['After Interpolation'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_interp = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After Interpolation'] = snr_after_interp\n",
    "print_snr_summary(snr_after_interp, \"After Channel Interpolation\")\n",
    "\n",
    "print(f\"\\nüìã Channel Status:\")\n",
    "print(f\"   Active channels: {len(raw_processed.ch_names)}\")\n",
    "print(f\"   Bad channels remaining: {len(raw_processed.info['bads'])}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "asr",
   "metadata": {},
   "source": [
    "### 5.8 Bad Time Segments Removal (Artifact Subspace Reconstruction) {#asr}\n",
    "\n",
    "**Purpose**: Automatically detect and correct brief periods of extreme artifacts that affect multiple channels simultaneously.\n",
    "\n",
    "**Why needed**: Even after other cleaning steps, occasional periods of extreme artifacts can remain (sudden movements, cable bumps, amplifier saturation). These brief but severe artifacts can distort statistical analyses and connectivity measures.\n",
    "\n",
    "**Method**: ASR learns the 'normal' signal patterns from clean calibration data, then identifies and reconstructs time periods where the signal deviates beyond a statistical threshold, effectively removing transient artifacts while preserving normal neural activity."
   ]
  },
  {
   "cell_type": "code",
   "id": "asr-removal",
   "metadata": {},
   "source": [
    "print(\"‚ö° Removing bad time segments using Artifact Subspace Reconstruction (ASR)...\")\n",
    "\n",
    "try:\n",
    "    from meegkit.asr import ASR\n",
    "    \n",
    "    # Get data for ASR\n",
    "    data = raw_processed.get_data() \n",
    "    sfreq = raw_processed.info['sfreq']\n",
    "    \n",
    "    # ASR parameters\n",
    "    asr_cutoff = 5      # Standard deviation cutoff (lower = more aggressive)\n",
    "    calibration_time = min(60, data.shape[0] / sfreq)  # Use first 60s or all data\n",
    "    \n",
    "    print(f\"   üîß ASR parameters: cutoff={asr_cutoff}, calibration={calibration_time:.1f}s\")\n",
    "    \n",
    "    # Initialize ASR\n",
    "    asr = ASR(sfreq=sfreq, cutoff=asr_cutoff)\n",
    "    \n",
    "    # Fit ASR on calibration data (clean segment)\n",
    "    calibration_samples = int(calibration_time * sfreq)\n",
    "    calibration_data = data[:calibration_samples, :]\n",
    "    asr.fit(calibration_data)\n",
    "    \n",
    "    # Apply ASR to the entire dataset\n",
    "    data_asr = asr.transform(data)\n",
    "    \n",
    "    # Calculate percentage of data reconstructed\n",
    "    reconstruction_ratio = np.mean(np.var(data - data_asr, axis=0) / np.var(data, axis=0))\n",
    "    \n",
    "    print(f\"   üìä Reconstruction ratio: {reconstruction_ratio:.1%}\")\n",
    "    \n",
    "    # Update raw data\n",
    "    raw_processed._data = data_asr.T  # Convert back to (channels x time)\n",
    "    \n",
    "    print(\"   ‚úÖ ASR applied successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è ASR failed: {e}\")\n",
    "    print(\"   Trying alternative bad segment removal...\")\n",
    "    \n",
    "    try:\n",
    "        # Alternative: simple artifact rejection based on amplitude\n",
    "        data = raw_processed.get_data()\n",
    "\n",
    "        # Flag samples whose absolute value exceeds threshold\n",
    "        amplitude_threshold = 5 * np.std(data)          # 5√ó RMS\n",
    "        bad_samples = np.any(np.abs(data) > amplitude_threshold, axis=0)\n",
    "\n",
    "        if np.any(bad_samples):\n",
    "            sfreq = raw_processed.info['sfreq']\n",
    "            bad_idx = np.where(bad_samples)[0]\n",
    "\n",
    "            # ‚îÄ‚îÄ‚îÄ group contiguous bad samples into segments ‚îÄ‚îÄ‚îÄ\n",
    "            breaks = np.where(np.diff(bad_idx) > 1)[0] + 1\n",
    "            segments = np.split(bad_idx, breaks)\n",
    "\n",
    "            onsets    = [seg[0] / sfreq for seg in segments]\n",
    "            durations = [len(seg) / sfreq for seg in segments]\n",
    "\n",
    "            # mark the segments as BAD_amplitude\n",
    "            bad_annot = mne.Annotations(onsets,\n",
    "                                        durations,\n",
    "                                        ['BAD_amplitude'] * len(onsets),\n",
    "                                        orig_time=raw_processed.info['meas_date'])\n",
    "            raw_processed.set_annotations(raw_processed.annotations + bad_annot)\n",
    "\n",
    "            print(f\"   üìç Marked {len(onsets)} bad segments \"\n",
    "                  f\"({bad_samples.sum()/len(bad_samples):.2%} of samples)\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ No samples exceeded the amplitude threshold\")\n",
    "\n",
    "        print(\"   ‚úÖ Alternative artifact rejection applied\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"   ‚ö†Ô∏è Alternative method also failed: {e2}\")\n",
    "        print(\"   Proceeding without bad segment removal\")\n",
    "\n",
    "# Store version\n",
    "raw_versions['After ASR'] = raw_processed.copy()\n",
    "\n",
    "# Quality assessment\n",
    "snr_after_asr = compute_snr(raw_processed, method='spectral')\n",
    "processing_log['After ASR'] = snr_after_asr\n",
    "print_snr_summary(snr_after_asr, \"After ASR\")\n",
    "\n",
    "# Plot comparison\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['After Interpolation'], raw_versions['After ASR']], \n",
    "    ['Before ASR', 'After ASR'],\n",
    "    \"PSD: Before vs After ASR\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "final-assessment",
   "metadata": {},
   "source": [
    "## 6. Final Quality Assessment {#final-assessment}\n",
    "\n",
    "**Purpose**: Evaluate the overall effectiveness of the preprocessing pipeline and document improvements.\n",
    "\n",
    "**Why needed**: It's crucial to verify that preprocessing actually improved data quality rather than inadvertently removing important neural signals. Quantitative metrics provide objective evidence of improvement and help optimize preprocessing parameters.\n",
    "\n",
    "**Methods**: Compare SNR across frequency bands before and after processing, visualize PSD changes, and generate comprehensive quality reports.\n",
    "\n",
    "Let's examine the overall improvement in data quality:"
   ]
  },
  {
   "cell_type": "code",
   "id": "final-quality-assessment",
   "metadata": {},
   "source": [
    "print(\"üìà Final Quality Assessment\")\nprint(\"=\" * 60)\n",
    "\n",
    "# Plot processing summary\n",
    "plot_processing_summary(processing_log)\n",
    "\n",
    "# Final comparison: Original vs Cleaned\n",
    "plot_psd_comparison(\n",
    "    [raw_versions['Original'], raw_versions['After ASR']], \n",
    "    ['Original Data', 'Fully Processed'],\n",
    "    \"Final Comparison: Original vs Cleaned EEG Data\"\n",
    ")\n",
    "\n",
    "# SNR improvement summary\n",
    "print(\"\\nüéØ SNR Improvement Summary:\")\nprint(\"=\" * 50)\n",
    "\n",
    "original_snr = processing_log['Original']\n",
    "final_snr = processing_log['After ASR']\n",
    "\n",
    "for band in ['delta', 'theta', 'alpha', 'beta', 'gamma']:\n",
    "    original_val = original_snr[band]['mean_snr']\n",
    "    final_val = final_snr[band]['mean_snr']\n",
    "    improvement = final_val - original_val\n",
    "    \n",
    "    print(f\"{band.capitalize():>8}: {original_val:6.2f} ‚Üí {final_val:6.2f} dB (Œî{improvement:+5.2f} dB)\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Data quality metrics\n",
    "print(\"\\nüìä Final Data Summary:\")\nprint(f\"‚îú‚îÄ‚îÄ Duration: {raw_processed.times[-1]:.1f} seconds\")\nprint(f\"‚îú‚îÄ‚îÄ Sampling rate: {raw_processed.info['sfreq']:.0f} Hz\")\nprint(f\"‚îú‚îÄ‚îÄ Channels: {len(raw_processed.ch_names)}\")\nprint(f\"‚îú‚îÄ‚îÄ Bad channels interpolated: {n_bad_channels}\")\nprint(f\"‚îî‚îÄ‚îÄ Processing completed successfully! ‚úÖ\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "saving",
   "metadata": {},
   "source": [
    "## 7. Saving Results {#saving}\n",
    "\n",
    "**Purpose**: Export cleaned data in multiple formats and generate comprehensive documentation of the preprocessing workflow.\n",
    "\n",
    "**Why needed**: Different analysis software requires different file formats. Documentation ensures reproducibility and helps track what preprocessing steps were applied. Quality metrics provide evidence of data improvement for publications.\n",
    "\n",
    "**Methods**: Save in common EEG formats (BrainVision, EEGLAB, EDF), generate HTML reports with MNE, and export quantitative quality metrics as CSV files.\n",
    "\n",
    "Save the cleaned data and generate a processing report:"
   ]
  },
  {
   "cell_type": "code",
   "id": "save-results",
   "metadata": {},
   "source": [
    "print(\"üíæ Saving processed data and reports...\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('cleaned_eeg_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Generate timestamp for filenames\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save cleaned data in multiple formats\n",
    "formats_to_save = {\n",
    "    'BrainVision': '.vhdr',\n",
    "    'EEGLAB': '.set', \n",
    "    'EDF': '.edf'\n",
    "}\n",
    "\n",
    "saved_files = []\n",
    "\n",
    "for format_name, extension in formats_to_save.items():\n",
    "    try:\n",
    "        output_file = output_dir / f'cleaned_eeg_{timestamp}{extension}'\n",
    "        \n",
    "        if extension == '.set':\n",
    "            # For EEGLAB format\n",
    "            raw_processed.save(output_file, overwrite=True, verbose=False)\n",
    "        else:\n",
    "            # For other formats using export\n",
    "            mne.export.export_raw(output_file, raw_processed, fmt='auto', overwrite=True, verbose=False)\n",
    "        \n",
    "        saved_files.append((format_name, output_file))\n",
    "        print(f\"   ‚úÖ Saved {format_name} format: {output_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Failed to save {format_name} format: {e}\")\n",
    "\n",
    "# Save processing report\n",
    "report_file = output_dir / f'processing_report_{timestamp}.html'\n",
    "\n",
    "try:\n",
    "    # Create an MNE Report\n",
    "    report = mne.Report(title='CleanEEG Processing Report')\n",
    "    \n",
    "    # Add original vs cleaned comparison\n",
    "    fig_comparison = plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot PSD comparison\n",
    "    raw_versions['Original'].compute_psd(fmax=50).plot(show=False)\n",
    "    plt.title('Original Data PSD')\n",
    "    report.add_figure(fig_comparison, title='Original Data PSD')\n",
    "    \n",
    "    fig_final = plt.figure(figsize=(12, 8))\n",
    "    raw_versions['After ASR'].compute_psd(fmax=50).plot(show=False)\n",
    "    plt.title('Cleaned Data PSD')\n",
    "    report.add_figure(fig_final, title='Cleaned Data PSD')\n",
    "    \n",
    "    # Add processing summary as text\n",
    "    processing_summary = f\"\"\"\n",
    "    # CleanEEG Processing Summary\n",
    "    \n",
    "    **Processing Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "    \n",
    "    **Input Data:**\n",
    "    - Duration: {raw.times[-1]:.1f} seconds\n",
    "    - Original sampling rate: {raw.info['sfreq']:.0f} Hz\n",
    "    - Channels: {len(raw.ch_names)}\n",
    "    \n",
    "    **Processing Steps Applied:**\n",
    "    1. Line noise removal (DSS at {line_freq} Hz)\n",
    "    2. Bandpass filter (1 Hz - 100 Hz)\n",
    "    3. Downsampling (to {raw_processed.info['sfreq']:.0f} Hz)\n",
    "    4. Bad channel detection ({n_bad_channels} channels found)\n",
    "    5. EOG artifact removal\n",
    "    6. Independent Component Analysis (ICA)\n",
    "    7. Bad channel interpolation\n",
    "    8. Artifact Subspace Reconstruction (ASR)\n",
    "    \n",
    "    **Output Data:**\n",
    "    - Final duration: {raw_processed.times[-1]:.1f} seconds\n",
    "    - Final sampling rate: {raw_processed.info['sfreq']:.0f} Hz\n",
    "    - Final channels: {len(raw_processed.ch_names)}\n",
    "    \"\"\"\n",
    "    \n",
    "    report.add_html(processing_summary, title='Processing Summary')\n",
    "    \n",
    "    # Save report\n",
    "    report.save(report_file, overwrite=True, open_browser=False)\n",
    "    print(f\"   üìã Processing report saved: {report_file.name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è Failed to create HTML report: {e}\")\n",
    "    \n",
    "    # Create a simple text report instead\n",
    "    text_report_file = output_dir / f'processing_summary_{timestamp}.txt'\n",
    "    with open(text_report_file, 'w') as f:\n",
    "        f.write(f\"CleanEEG Processing Summary\\n\")\n",
    "        f.write(f\"Generated: {datetime.now()}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Input Data:\\n\")\n",
    "        f.write(f\"- Duration: {raw.times[-1]:.1f} seconds\\n\")\n",
    "        f.write(f\"- Sampling rate: {raw.info['sfreq']:.0f} Hz\\n\")\n",
    "        f.write(f\"- Channels: {len(raw.ch_names)}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Output Data:\\n\")\n",
    "        f.write(f\"- Duration: {raw_processed.times[-1]:.1f} seconds\\n\")\n",
    "        f.write(f\"- Sampling rate: {raw_processed.info['sfreq']:.0f} Hz\\n\")\n",
    "        f.write(f\"- Channels: {len(raw_processed.ch_names)}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"SNR Improvements:\\n\")\n",
    "        for band in ['delta', 'theta', 'alpha', 'beta', 'gamma']:\n",
    "            original_val = processing_log['Original'][band]['mean_snr']\n",
    "            final_val = processing_log['After ASR'][band]['mean_snr']\n",
    "            improvement = final_val - original_val\n",
    "            f.write(f\"- {band.capitalize()}: {original_val:.2f} ‚Üí {final_val:.2f} dB (Œî{improvement:+.2f} dB)\\n\")\n",
    "    \n",
    "    print(f\"   üìÑ Text summary saved: {text_report_file.name}\")\n",
    "\n",
    "# Save SNR data as CSV\n",
    "snr_csv_file = output_dir / f'snr_data_{timestamp}.csv'\n",
    "snr_df_list = []\n",
    "\n",
    "for step_name, snr_data in processing_log.items():\n",
    "    for band, band_data in snr_data.items():\n",
    "        snr_df_list.append({\n",
    "            'processing_step': step_name,\n",
    "            'frequency_band': band,\n",
    "            'mean_snr_db': band_data['mean_snr'],\n",
    "            'std_snr_db': band_data['std_snr']\n",
    "        })\n",
    "\n",
    "snr_df = pd.DataFrame(snr_df_list)\n",
    "snr_df.to_csv(snr_csv_file, index=False)\n",
    "print(f\"   üìä SNR data saved: {snr_csv_file.name}\")\n",
    "\n",
    "print(f\"\\nüéâ Processing completed successfully!\")\n",
    "print(f\"üìÅ All files saved to: {output_dir.absolute()}\")\n",
    "print(f\"\\nüìã Saved files:\")\n",
    "for format_name, file_path in saved_files:\n",
    "    print(f\"   - {format_name}: {file_path.name}\")\n",
    "print(f\"   - SNR Data: {snr_csv_file.name}\")\n",
    "print(f\"   - Report: {report_file.name if 'report_file' in locals() else text_report_file.name}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "üéâ **Congratulations!** You have successfully completed the CleanEEG preprocessing pipeline.\n",
    "\n",
    "### What we accomplished:\n",
    "\n",
    "1. **Loaded and inspected** your EEG data\n",
    "2. **Applied comprehensive preprocessing** following the DISCOVER-EEG framework:\n",
    "   - Line noise removal using Denoising Source Separation\n",
    "   - Highpass filtering to remove slow drifts\n",
    "   - Downsampling for computational efficiency\n",
    "   - Automatic bad channel detection using PREP pipeline\n",
    "   - EOG artifact removal (if channels available)\n",
    "   - Independent Component Analysis with automatic classification\n",
    "   - Bad channel interpolation\n",
    "   - Bad time segment removal using Artifact Subspace Reconstruction\n",
    "\n",
    "3. **Monitored data quality** throughout the pipeline using SNR metrics\n",
    "4. **Saved cleaned data** in multiple formats for further analysis\n",
    "5. **Generated comprehensive reports** documenting the preprocessing steps\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "Your cleaned EEG data is now ready for:\n",
    "- **Spectral analysis** (power spectral density, frequency band analysis)\n",
    "- **Connectivity analysis** (coherence, phase-amplitude coupling)\n",
    "- **Event-related potential analysis** (if you have event markers)\n",
    "- **Machine learning applications** (classification, regression)\n",
    "- **Source localization** (if you have a forward model)\n",
    "\n",
    "### Tips for further analysis:\n",
    "\n",
    "- The cleaned data maintains the original channel structure and timing\n",
    "- All preprocessing steps are documented in the generated reports\n",
    "- SNR improvements indicate the effectiveness of each preprocessing step\n",
    "- Consider the specific requirements of your analysis when choosing output formats\n",
    "\n",
    "**Happy analyzing!** üß†‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
